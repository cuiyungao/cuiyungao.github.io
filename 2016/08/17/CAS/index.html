<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Consensus Attention-based Neural Networks for Chinese Reading Comprehension | Cuiyun Gao&#39;s Daily Digest | Work Hard, and Play Harder. 如果有一天：你不再寻找爱情，只是去爱；你不再渴望成功，只是去做；你不再追求成长，只是去修行；一切才真正开始~！</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="theme-color" content="#3F51B5">
  
  
  <meta name="keywords" content="RNN,Deep Learning,NLP,Attention Model">
  <meta name="description" content="Cui, Y., Liu, T., Chen, Z., Wang, S., &amp;amp; Hu, G. (2016). Consensus Attention-based Neural Networks for Chinese Reading Comprehension. arXiv preprint arXiv:1607.02250.">
<meta property="og:type" content="article">
<meta property="og:title" content="Consensus Attention-based Neural Networks for Chinese Reading Comprehension">
<meta property="og:url" content="http://cuiyungao.github.io/2016/08/17/CAS/index.html">
<meta property="og:site_name" content="Cuiyun Gao's Daily Digest">
<meta property="og:description" content="Cui, Y., Liu, T., Chen, Z., Wang, S., &amp;amp; Hu, G. (2016). Consensus Attention-based Neural Networks for Chinese Reading Comprehension. arXiv preprint arXiv:1607.02250.">
<meta property="og:image" content="http://cuiyungao.github.io/img/daily/CAS1.png">
<meta property="og:image" content="http://cuiyungao.github.io/img/daily/CAS2.png">
<meta property="og:updated_time" content="2016-08-17T08:29:05.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Consensus Attention-based Neural Networks for Chinese Reading Comprehension">
<meta name="twitter:description" content="Cui, Y., Liu, T., Chen, Z., Wang, S., &amp;amp; Hu, G. (2016). Consensus Attention-based Neural Networks for Chinese Reading Comprehension. arXiv preprint arXiv:1607.02250.">
<meta name="twitter:image" content="http://cuiyungao.github.io/img/daily/CAS1.png">
  
    <link rel="alternative" href="/atom.xml" title="Cuiyun Gao&#39;s Daily Digest" type="application/atom+xml">
  
  <meta name="summary" content="&lt;p&gt;Cui, Y., Liu, T., Chen, Z., Wang, S., &amp;amp; Hu, G. (2016). Consensus Attention-based Neural Networks for Chinese Reading Comprehension. arXiv preprint arXiv:1607.02250.&lt;/p&gt;">
  <link rel="shortcut icon" href="/img/favicon.png">
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="loading" class="active"></div>

  <nav id="menu" class="hide" >
   <div class="inner flex-row-vertical">
  <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
      <i class="icon icon-lg icon-close"></i>
  </a>
  <div class="brand-wrap">
    <div class="brand">
      <a href="/" class="avatar"><img src="/img/head.jpg"></a>
      <hgroup class="introduce">
        <h5 class="nickname">Cuiyun Gao</h5>
        <a href="mailto:undefined" title="cygao@cse.cuhk.edu.hk" class="mail">cygao@cse.cuhk.edu.hk</a>
      </hgroup>
    </div>
  </div>
  <ul class="nav flex-col">
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-My Home"></i>
            My Home
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-Paper Reading"></i>
            Paper Reading
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-Daily Digest"></i>
            Daily Digest
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-My Works"></i>
            My Works
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-About Me"></i>
            About Me
          </a>
        </li>
    
  </ul>

  <footer class="footer">
  <p><a rel="license" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0;vertical-align:middle;" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAAAPCAMAAABEF7i9AAAAllBMVEUAAAD///+rsapERER3d3eIiIjMzMzu7u4iIiKUmZO6v7rKzsoODg4RERFVVVUNDQ0NDg0PEA8zMzNLTEtbXltmZmZydnF9gn2AgICPkI+ZmZmqqqq7u7vFxsXIzMgNDQwZGRkgICAhISEkJSMnKCcuMC4xMzE5Ozk7PTtBQkFCQkJDQ0Nna2eGhoaHh4ezuLLGysbd3d1wVGpAAAAA4UlEQVR42q2T1xqCMAyFk7QsBQeKA9x7j/d/OSm22CpX0nzcpA1/T05aAOuBVkMAScQFHLnEwoCo2f1TnQIGoVMewjZEjVFN4GH1Ue1Cn2jWqwfsOOj6wDwGvotsl/c8lv7KIq1eLOsT0HMFHMIE/RZyHnlphryT9zyV+8WH5e8yQw3wnQvgAFxPTKUVi555SHR/lOfLMgVTeDlSfN+TaoUsiTyeIm+bCkHvCA2FUKG48LDtYBZBknsYP/G8NTw0gaaHyuQf4H5pecrB/FYCT2sL9zAfy1Xyjou6L8X2W7YcLyBZCRtnq/zfAAAAAElFTkSuQmCC" /></a></p>
  <p>Cuiyun Gao&#39;s Daily Digest &copy; 2016</p>
  <p>Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme
  <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a></p>
  <a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-2x icon-rss-square"></i></a>
</footer>

</div>

  </nav>
  <main id="main">
    <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Consensus Attention-based Neural Networks for Chinese Reading Comprehension</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input " autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
    </div>
</header>
<header class="content-header">
  <div class="container">
    <h1 class="author">Consensus Attention-based Neural Networks for Chinese Reading Comprehension</h1>
    <h5 class="subtitle">
        
            <time datetime="2016-08-17T06:51:22.000Z" itemprop="datePublished" class="page-time">
  2016-08-17
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/papers/">papers</a></li></ul>

        
    </h5>
  </div>
</header>

    <div class="container body-wrap">
      <article id="post-CAS" 
  class="article article-type-post" itemprop="blogPost">
    <div class="post-meat flex-row">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Attention-Model/">Attention Model</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/RNN/">RNN</a></li></ul>

    </div>
    <div class="post-body">
        <aside class="post-widget" id="post-widget">

            

            
            <nav class="post-toc-wrap" id="post-toc">
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Problem-Definition"><span class="post-toc-text">Problem Definition</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Consensus-Attention-Sum-Reader"><span class="post-toc-text">Consensus Attention Sum Reader</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Experiments"><span class="post-toc-text">Experiments</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Reference"><span class="post-toc-text">Reference</span></a></li></ol>
            </nav>
            
        </aside>

        <div class="post-main">

            <div class="post-content" id="post-content" itemprop="postContent">
            <p>Cui, Y., Liu, T., Chen, Z., Wang, S., &amp; Hu, G. (2016). Consensus Attention-based Neural Networks for Chinese Reading Comprehension. arXiv preprint arXiv:1607.02250.</p>
<a id="more"></a>
<p>这篇文章是哈工大与科大讯飞合作的作品。文章的主要贡献在于：</p>
<ol>
<li>提供了中文阅读理解的数据集，包括人民日报新闻 (People Daily news)和儿童童话 (Children’s Fairy Tale, CFT)；</li>
<li>完善了已有的attention-based NN model，提出了consensus attention-based neural network architecture，即consensus attention sum reader (CAS Reader)。</li>
</ol>
<h3 id="Problem-Definition"><a href="#Problem-Definition" class="headerlink" title="Problem Definition"></a><center><strong>Problem Definition</strong></center></h3><p><code>Cloze-style reading comprehension problem</code>致力于理解给定的上下文或者文档，回答根据文档的属性所得的问题，并且回答是文档当中存在的一个词。可以由下面的三元组表示：<br>$&lt;\mathcal{D}, \mathcal{Q}, \mathcal{A}&gt;$，<br>其中$\mathcal{D}$为文档，$\mathcal{Q}$为query，$\mathcal{A}$为针对query的回答。</p>
<p>这种问题的解决通常采用attention-based neural network的方法，但是这种方法需要<mark>大量的训练数据</mark>来训练预测的可靠模型。现有的方法是自动地生成大量的训练数据。</p>
<h3 id="Consensus-Attention-Sum-Reader"><a href="#Consensus-Attention-Sum-Reader" class="headerlink" title="Consensus Attention Sum Reader"></a><center><strong>Consensus Attention Sum Reader</strong></center></h3><p>本文的算法是基于[2]的改进，目的是直接从文档中估计答案，而不是从所有的vocabularies估计。作者发现<mark>直接将query进行RNN之后的表示形式不足以表示query的整个信息</mark>，作者利用query的每一个<code>time slices</code>，建立了不同steps之间的<code>consensus attention</code>。<mark>感觉最近是不是attention上的LSTM很火？这个可以改善一些常见的topic么？</mark></p>
<p>一般形式是，给定一组训练三元组$&lt;\mathcal{D}, \mathcal{Q}, \mathcal{A}&gt;$，首先将文档$\mathcal{D}$和query $\mathcal{Q}$的one-hot表示形式转换成共享embedding matrix $W_e$的连续的表示形式。<mark>由于query通常比文档短，通过共享embedding weights，query的表示形式可以受益于文档的表示形式</mark>，这比分开的embedding matrices有效。</p>
<p>之后，用两个不同的<code>bi-directional RNNs</code>得到文档和query的上下文表示形式。<mark>这种方法可以获取之前和之后的上下文信息。</mark>文章采用bi-directional Gated Recurrent Unit (GRU)，如下：<br>$$<br>e(x) = W_e\times x, \; where \, x\in\mathcal{D,Q} \\<br>\overrightarrow{h_s} = \overrightarrow{GRU}(e(x)) \\<br>\overleftarrow{h_s} = \overleftarrow{GRU}(e(x)) \\<br>h_s = [\overrightarrow{h_s};\overleftarrow{h_s}].<br>$$</p>
<p>文档的<code>attention</code>即一个概率分布，这里用$h_{doc}$和$h_{query}$分别表示文档和query的上下文表示形式，都是三维的张量。这两个张量的内积表示每个文档单词在时间$t$对query单词的重要性。概率分布用softmax来获得，即：<br>$$<br>\alpha(t) = softmax(h_{doc}\odot h_{query}(t)).<br>$$</p>
<p>$\alpha(t)$即文档的<code>attention</code>，且$\alpha(t)=[\alpha(t)_1,\alpha(t)_2, …, \alpha(t)_n]$，$\alpha(t)_i$指的是文档第$i$个词在时间$t$的attention值。<code>Consensus attention</code>由merging function $f$得到，即：<br>$$<br>s=f(\alpha(1), …,\alpha(m)),<br>$$<br>其中，$s$是query最终的attention，$m$是query的长度。Merging function有以下几种heuristics，即：<br>$$<br>   s\propto<br>   \begin{cases}<br>    softmax(\sum_{t=1}^m \alpha(t)),\; if \, mode=sum; \\<br>    softmax(\frac{1}{m}\sum_{t=1}^m \alpha(t)), \; if \, mode=avg; \\<br>    softmax({max}_{t=1,…,m} \alpha(t)_i), \; if \, mode=max.<br>   \end{cases}<br>$$</p>
<p>最终，将结果$s$映射到vocabulary space $V$，并将在文档中同一个词出现在不同位置的attention value相加，如下式所示。（<mark>思考：这个方式跟直接从vocabulary中选取某个词有啥区别？因为文章的一个亮点是从文档当中选取，而不是从vocabularies当中选取。</mark>）</p>
<p>$$<br>P(w|\mathcal{D,Q})=\sum_{i\in I(w,\mathcal{D})} s_i, \, w\in V.<br>$$<br>其中，$I(w,\mathcal{D})$为单词$w$出现在文档$\mathcal{D}$中的位置。整个框架图由下图所示。</p>
<center><img src="/img/daily/CAS1.png" width="100%"></center><br><center>Fig.1 Architecture of the Proposed Consensus Attention Sum Reader (CAS Reader).</center>

<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a><center><strong>Experiments</strong></center></h3><p>框架实现采用Theano和Keras，在Tesla K40 GPU上训练。实验结果在某些数据集上要优于传统的不用Consensus的模型，结果不好的原因是以前的模型只是从entity当中挑选答案，而改进之后的模型是从文档当中选取。在中文分词上的结果表明，有Consensus的Model要优于传统的attention model，结果如下图所示。</p>
<center><img src="/img/daily/CAS2.png" width="80%"></center>

<p>文章另外一个有意思的点是，<mark>机器生成的问题跟人想问的问题不同，对人的问题产生效果比较差</mark>。比如，机器问题“I went to the <em>__</em> this morning .”，而人的问题是“Where did I go this morning ?”。<mark>我比较疑惑的是，这两个问题在中文里面不是一样么？只是加了一个语气词而已，那么效果怎么会差这么大？</mark></p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><center><strong>Reference</strong></center></h3><p>[1] <a href="https://arxiv.org/abs/1607.02250" target="_blank" rel="external">Consensus Attention-based Neural Networks for Chinese Reading Comprehension</a><br>[2] <a href="https://arxiv.org/abs/1603.01547" target="_blank" rel="external">Text Understanding with the Attention Sum Reader Network</a></p>

            <blockquote>
                <p>
                Permalink：
                <a href="http://cuiyungao.github.io/2016/08/17/CAS/" target="_blank" rel="external">http://cuiyungao.github.io/2016/08/17/CAS/</a>
                </p>
                <footer><cite><a href="http://cuiyungao.github.io">@Cuiyun Gao's Daily Digest</a></cite></footer>
            </blockquote>
            </div>
            
<nav class="post-nav">
  
    <div class="waves-block waves-effect prev fl">
      <a href="/2016/08/17/adblock/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">What to do about Ad Blocking Impact on Customer Experience?</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next fr">
      <a href="/2016/08/16/arxiv0810/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond</h4>
      </a>
    </div>
  
</nav>


            
            
<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="CAS" data-title="Consensus Attention-based Neural Networks for Chinese Reading Comprehension" data-url="http://cuiyungao.github.io/2016/08/17/CAS/index.html"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"cuiyungao"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>





        </div>
    </div>
</article>
    </div>
  </main>
<div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>


<script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>

<script src="/js/main.js"></script>



<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<script type="text/template" id="search-tpl">
<li class="item">
    <a href="/{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</script>

<script src="/js/search.js"></script>



<! -- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->








</body>
</html>
