<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Softmax Approximations for Learning Word Embeddings and Language Modeling | Cuiyun Gao&#39;s Daily Digest | Work Hard, and Play Harder. 如果有一天：你不再寻找爱情，只是去爱；你不再渴望成功，只是去做；你不再追求成长，只是去修行；一切才真正开始~！</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="theme-color" content="#3F51B5">
  
  
  <meta name="keywords" content="NLP">
  <meta name="description" content="本文主要介绍了softmax在word embedding方面的应用，资料来源于这里。">
<meta property="og:type" content="article">
<meta property="og:title" content="Softmax Approximations for Learning Word Embeddings and Language Modeling">
<meta property="og:url" content="http://cuiyungao.github.io/2016/08/19/softmax/index.html">
<meta property="og:site_name" content="Cuiyun Gao's Daily Digest">
<meta property="og:description" content="本文主要介绍了softmax在word embedding方面的应用，资料来源于这里。">
<meta property="og:image" content="http://cuiyungao.github.io/img/daily/softmax1.png">
<meta property="og:image" content="http://cuiyungao.github.io/img/daily/softmax2.png">
<meta property="og:image" content="http://cuiyungao.github.io/img/daily/softmax3.png">
<meta property="og:image" content="http://cuiyungao.github.io/img/daily/softmax4.png">
<meta property="og:image" content="http://cuiyungao.github.io/img/daily/softmax5.png">
<meta property="og:updated_time" content="2016-08-21T09:20:12.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Softmax Approximations for Learning Word Embeddings and Language Modeling">
<meta name="twitter:description" content="本文主要介绍了softmax在word embedding方面的应用，资料来源于这里。">
<meta name="twitter:image" content="http://cuiyungao.github.io/img/daily/softmax1.png">
  
    <link rel="alternative" href="/atom.xml" title="Cuiyun Gao&#39;s Daily Digest" type="application/atom+xml">
  
  <meta name="summary" content="&lt;p&gt;本文主要介绍了softmax在word embedding方面的应用，资料来源于&lt;a href=&quot;http://www.slideshare.net/SebastianRuder/softmax-approximations-for-learning-word-embeddings-and-language-modeling-sebastian-ruder&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;">
  <link rel="shortcut icon" href="/img/favicon.png">
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="loading" class="active"></div>

  <nav id="menu" class="hide" >
   <div class="inner flex-row-vertical">
  <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
      <i class="icon icon-lg icon-close"></i>
  </a>
  <div class="brand-wrap">
    <div class="brand">
      <a href="/" class="avatar"><img src="/img/head.jpg"></a>
      <hgroup class="introduce">
        <h5 class="nickname">Cuiyun Gao</h5>
        <a href="mailto:undefined" title="cygao@cse.cuhk.edu.hk" class="mail">cygao@cse.cuhk.edu.hk</a>
      </hgroup>
    </div>
  </div>
  <ul class="nav flex-col">
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-My Home"></i>
            My Home
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-Paper Reading"></i>
            Paper Reading
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-Daily Digest"></i>
            Daily Digest
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-My Works"></i>
            My Works
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-About Me"></i>
            About Me
          </a>
        </li>
    
  </ul>

  <footer class="footer">
  <p><a rel="license" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0;vertical-align:middle;" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAAAPCAMAAABEF7i9AAAAllBMVEUAAAD///+rsapERER3d3eIiIjMzMzu7u4iIiKUmZO6v7rKzsoODg4RERFVVVUNDQ0NDg0PEA8zMzNLTEtbXltmZmZydnF9gn2AgICPkI+ZmZmqqqq7u7vFxsXIzMgNDQwZGRkgICAhISEkJSMnKCcuMC4xMzE5Ozk7PTtBQkFCQkJDQ0Nna2eGhoaHh4ezuLLGysbd3d1wVGpAAAAA4UlEQVR42q2T1xqCMAyFk7QsBQeKA9x7j/d/OSm22CpX0nzcpA1/T05aAOuBVkMAScQFHLnEwoCo2f1TnQIGoVMewjZEjVFN4GH1Ue1Cn2jWqwfsOOj6wDwGvotsl/c8lv7KIq1eLOsT0HMFHMIE/RZyHnlphryT9zyV+8WH5e8yQw3wnQvgAFxPTKUVi555SHR/lOfLMgVTeDlSfN+TaoUsiTyeIm+bCkHvCA2FUKG48LDtYBZBknsYP/G8NTw0gaaHyuQf4H5pecrB/FYCT2sL9zAfy1Xyjou6L8X2W7YcLyBZCRtnq/zfAAAAAElFTkSuQmCC" /></a></p>
  <p>Cuiyun Gao&#39;s Daily Digest &copy; 2016</p>
  <p>Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme
  <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a></p>
  <a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-2x icon-rss-square"></i></a>
</footer>

</div>

  </nav>
  <main id="main">
    <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Softmax Approximations for Learning Word Embeddings and Language Modeling</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input " autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
    </div>
</header>
<header class="content-header">
  <div class="container">
    <h1 class="author">Softmax Approximations for Learning Word Embeddings and Language Modeling</h1>
    <h5 class="subtitle">
        
            <time datetime="2016-08-19T14:39:25.000Z" itemprop="datePublished" class="page-time">
  2016-08-19
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/daily/">daily</a></li></ul>

        
    </h5>
  </div>
</header>

    <div class="container body-wrap">
      <article id="post-softmax" 
  class="article article-type-post" itemprop="blogPost">
    <div class="post-meat flex-row">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li></ul>

    </div>
    <div class="post-body">
        <aside class="post-widget" id="post-widget">

            

            
            <nav class="post-toc-wrap" id="post-toc">
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Language-Modeling-Objective"><span class="post-toc-text">Language Modeling Objective</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Softmax-based-Approaches"><span class="post-toc-text">Softmax-based Approaches</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#sampling-based-Approaches"><span class="post-toc-text">sampling-based Approaches</span></a></li></ol>
            </nav>
            
        </aside>

        <div class="post-main">

            <div class="post-content" id="post-content" itemprop="postContent">
            <p>本文主要介绍了softmax在word embedding方面的应用，资料来源于<a href="http://www.slideshare.net/SebastianRuder/softmax-approximations-for-learning-word-embeddings-and-language-modeling-sebastian-ruder" target="_blank" rel="external">这里</a>。</p>
<a id="more"></a>
<h3 id="Language-Modeling-Objective"><a href="#Language-Modeling-Objective" class="headerlink" title="Language Modeling Objective"></a><center><strong>Language Modeling Objective</strong></center></h3><p>语言模型的目标是最大化给定词$w_t$的前$n$个单词预测当前词的概率，即$p(w_t|w_{t-1},…,w_{t-n+1})$。对于n-gram models，即:<br>$$<br>p(w_t|w_{t-1},…,w_{t-n+1})=\frac{count(w_{t-n+1},…,w_{t-1},w_t)}{count(w_{t-n+1},..,w_{t-1})},<br>$$<br>对于神经网络，即：<br>$$<br>p(w_t|w_{t-1},…,w_{t-n+1})=\frac{exp(h^Tv_w)}{\sum_{w_i\in V}exp(h^Tv_{w_i})}.<br>$$</p>
<p>Maximum entropy models最小化同一个概率分布，即$P_h(y|x)=\frac{exp(h\cdot f(x,y))}{\sum_{y^{\prime}\in y}exp(h\cdot f(x,y^{\prime}))}$,其中$h$是一个<code>weight vector</code>，$f(x,y)$是一个feature vector。在神经网络中经常用于：</p>
<ul>
<li>Multi-class分类；</li>
<li>“Soft” selection, 比如attention, memory retrievals等。</li>
</ul>
<p>分母经常被叫做<code>partition function</code>,即$Z=\sum_{w_i\in V}exp(h^Tv_{w_i})$。<code>Softmax-based approaches</code>保持了softmax层的完整性，使得算法更高效；而<code>sampling-based approaches</code>优化估计softmax的不同的loss函数。</p>
<h3 id="Softmax-based-Approaches"><a href="#Softmax-based-Approaches" class="headerlink" title="Softmax-based Approaches"></a><center><strong>Softmax-based Approaches</strong></center></h3><p><code>Hierarchical softmax</code>可以被看做是一个二叉树，最多估计$log_2|V|$个节点，而不是所有的$|V|$个节点，如图Fig.1所示。结构比较重要，可以快速地遍历点，经常使用的结构是<code>Huffman tree</code>，对于frequent words路径短，如图Fig.2所示。</p>
<center><img src="/img/daily/softmax1.png" width="80%"></center><br><center>Fig.1 Hierarchical Softmax</center><br><center><img src="/img/daily/softmax2.png" width="80%"></center><br><center>Fig.2 Hierarchical Softmax [Mnih and Hinton, 2008]</center>

<p><code>Differentiated Softmax</code>的出发点是我们对于经常出现的词获取的知识较多，但是对于很少出现的词信息较少，这就导致前者可以学习较多的参数，而后者较少，最终导致每个输出单词的embedding的大小不同。频繁出现的词的embedding较大，而很少出现的词的embedding较小。框架图如图Fig.3所示。</p>
<center><img src="/img/daily/softmax3.png" width="50%"></center><br><center>Fig.3 Differentiated Softmax [Chen et al., 2015]</center>

<p><code>CNN-Softmax</code>学习产生word embedding的函数，而不是单独学习所有输出单词的embedding，如图Fig.4所示。</p>
<center><img src="/img/daily/softmax4.png" width="40%"></center><br><center>Fig.3 CNN-Softmax [Jozefowicz et al., 2016]</center>

<h3 id="sampling-based-Approaches"><a href="#sampling-based-Approaches" class="headerlink" title="sampling-based Approaches"></a><center><strong>sampling-based Approaches</strong></center></h3><p><code>Margin-based Hinge Loss</code>的出发点是只学习两种分类，一种是正确的词，一种是不正确的词。正确的词的得分较高，不正确的词的得分较低，即最大化：<br>$$<br>\sum_{x\in X}\sum_{w\in V}max{(0,1-f(x)+f(x^{(w)})},<br>$$<br>其中，$x^{(w)}$是一个<code>corrupted</code> window (目标词由任意的词来代替)，$f(x)$是模型输出的分数。</p>
<p><code>Noise Contrastive Estimation</code>的目的是将target word跟noise区分开，如图Fig.5所示。这样语言模型被转化为二分类模型，对于每个词按照一定的噪声分布（比如，unigram）获取$k$个噪声采样点，用logistic regression loss最小化cross-entropy函数。随着$k$数目的增长估计softmax。</p>
<center><img src="/img/daily/softmax5.png" width="80%"></center><br><center>Fig.5 Noise Contrastive Estimation (NCE) [Mnih and Teh, 2012]</center>

            <blockquote>
                <p>
                Permalink：
                <a href="http://cuiyungao.github.io/2016/08/19/softmax/" target="_blank" rel="external">http://cuiyungao.github.io/2016/08/19/softmax/</a>
                </p>
                <footer><cite><a href="http://cuiyungao.github.io">@Cuiyun Gao's Daily Digest</a></cite></footer>
            </blockquote>
            </div>
            
<nav class="post-nav">
  
    <div class="waves-block waves-effect prev fl">
      <a href="/2016/08/21/backpro/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">A Derivation of Backpropagation in Matrix Form</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next fr">
      <a href="/2016/08/19/fasttext/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">FAIR Open-Sources fastText</h4>
      </a>
    </div>
  
</nav>


            
            
<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="softmax" data-title="Softmax Approximations for Learning Word Embeddings and Language Modeling" data-url="http://cuiyungao.github.io/2016/08/19/softmax/index.html"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"cuiyungao"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>





        </div>
    </div>
</article>
    </div>
  </main>
<div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>


<script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>

<script src="/js/main.js"></script>



<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<script type="text/template" id="search-tpl">
<li class="item">
    <a href="/{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</script>

<script src="/js/search.js"></script>



<! -- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->








</body>
</html>
