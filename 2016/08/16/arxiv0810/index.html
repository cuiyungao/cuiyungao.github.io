<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond | Cuiyun Gao&#39;s Daily Digest | Work Hard, and Play Harder. 如果有一天：你不再寻找爱情，只是去爱；你不再渴望成功，只是去做；你不再追求成长，只是去修行；一切才真正开始~！</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="theme-color" content="#3F51B5">
  
  
  <meta name="keywords" content="RNN,NLP,Deep Learning">
  <meta name="description" content="IBM的作品。Nallapati, R., Zhou, B., glar Gulçehre, Ç., &amp;amp; Xiang, B. Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond.">
<meta property="og:type" content="article">
<meta property="og:title" content="Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond">
<meta property="og:url" content="http://cuiyungao.github.io/2016/08/16/arxiv0810/index.html">
<meta property="og:site_name" content="Cuiyun Gao's Daily Digest">
<meta property="og:description" content="IBM的作品。Nallapati, R., Zhou, B., glar Gulçehre, Ç., &amp;amp; Xiang, B. Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond.">
<meta property="og:image" content="http://cuiyungao.github.io/img/daily/arxiv08101.png">
<meta property="og:image" content="http://cuiyungao.github.io/img/daily/arxiv08102.png">
<meta property="og:updated_time" content="2016-08-17T01:21:43.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond">
<meta name="twitter:description" content="IBM的作品。Nallapati, R., Zhou, B., glar Gulçehre, Ç., &amp;amp; Xiang, B. Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond.">
<meta name="twitter:image" content="http://cuiyungao.github.io/img/daily/arxiv08101.png">
  
    <link rel="alternative" href="/atom.xml" title="Cuiyun Gao&#39;s Daily Digest" type="application/atom+xml">
  
  <meta name="summary" content="&lt;p&gt;IBM的作品。Nallapati, R., Zhou, B., glar Gulçehre, Ç., &amp;amp; Xiang, B. Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond.&lt;/p&gt;">
  <link rel="shortcut icon" href="/img/favicon.png">
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="loading" class="active"></div>

  <nav id="menu" class="hide" >
   <div class="inner flex-row-vertical">
  <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
      <i class="icon icon-lg icon-close"></i>
  </a>
  <div class="brand-wrap">
    <div class="brand">
      <a href="/" class="avatar"><img src="/img/head.jpg"></a>
      <hgroup class="introduce">
        <h5 class="nickname">Cuiyun Gao</h5>
        <a href="mailto:undefined" title="cygao@cse.cuhk.edu.hk" class="mail">cygao@cse.cuhk.edu.hk</a>
      </hgroup>
    </div>
  </div>
  <ul class="nav flex-col">
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-Home"></i>
            My Home
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/categories/papers"  >
            <i class="icon icon-lg icon-Reading"></i>
            Paper Reading
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/categories/daily"  >
            <i class="icon icon-lg icon-Daily"></i>
            Daily Digest
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-Works"></i>
            My Works
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-About"></i>
            About Me
          </a>
        </li>
    
  </ul>

  <footer class="footer">
  <p><a rel="license" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0;vertical-align:middle;" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAAAPCAMAAABEF7i9AAAAllBMVEUAAAD///+rsapERER3d3eIiIjMzMzu7u4iIiKUmZO6v7rKzsoODg4RERFVVVUNDQ0NDg0PEA8zMzNLTEtbXltmZmZydnF9gn2AgICPkI+ZmZmqqqq7u7vFxsXIzMgNDQwZGRkgICAhISEkJSMnKCcuMC4xMzE5Ozk7PTtBQkFCQkJDQ0Nna2eGhoaHh4ezuLLGysbd3d1wVGpAAAAA4UlEQVR42q2T1xqCMAyFk7QsBQeKA9x7j/d/OSm22CpX0nzcpA1/T05aAOuBVkMAScQFHLnEwoCo2f1TnQIGoVMewjZEjVFN4GH1Ue1Cn2jWqwfsOOj6wDwGvotsl/c8lv7KIq1eLOsT0HMFHMIE/RZyHnlphryT9zyV+8WH5e8yQw3wnQvgAFxPTKUVi555SHR/lOfLMgVTeDlSfN+TaoUsiTyeIm+bCkHvCA2FUKG48LDtYBZBknsYP/G8NTw0gaaHyuQf4H5pecrB/FYCT2sL9zAfy1Xyjou6L8X2W7YcLyBZCRtnq/zfAAAAAElFTkSuQmCC" /></a></p>
  <p>Cuiyun Gao&#39;s Daily Digest &copy; 2016</p>
  <p>Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme
  <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a></p>
  <a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-2x icon-rss-square"></i></a>
</footer>

</div>

  </nav>
  <main id="main">
    <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input " autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
    </div>
</header>
<header class="content-header">
  <div class="container">
    <h1 class="author">Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond</h1>
    <h5 class="subtitle">
        
            <time datetime="2016-08-16T09:16:51.000Z" itemprop="datePublished" class="page-time">
  2016-08-16
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/papers/">papers</a></li></ul>

        
    </h5>
  </div>
</header>

    <div class="container body-wrap">
      <article id="post-arxiv0810" 
  class="article article-type-post" itemprop="blogPost">
    <div class="post-meat flex-row">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/RNN/">RNN</a></li></ul>

    </div>
    <div class="post-body">
        <aside class="post-widget" id="post-widget">

            

            
            <nav class="post-toc-wrap" id="post-toc">
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Contribution"><span class="post-toc-text">Contribution</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Models"><span class="post-toc-text">Models</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Experiments"><span class="post-toc-text">Experiments</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Reference"><span class="post-toc-text">Reference</span></a></li></ol>
            </nav>
            
        </aside>

        <div class="post-main">

            <div class="post-content" id="post-content" itemprop="postContent">
            <p>IBM的作品。Nallapati, R., Zhou, B., glar Gulçehre, Ç., &amp; Xiang, B. Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond.</p>
<a id="more"></a>
<p>所谓的<code>abstractive text summarization</code>就是压缩原始的文档，并保留原文档的主要概念。</p>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a><center><strong>Contribution</strong></center></h3><p>文章将在MT (Machine Learning)中的Attentional Encoder-Decoder RNN算法应用到abstractive text summarization，并针对在abstractive text summarization中存在的三个问题（即为<mark>key-words建模，获取sentence-to-word的结构层级，和在training阶段处理少见的或者没有见过的词</mark>）对模型进行改善。</p>
<p>文章的另外一个贡献是提出了新的包含多句子总结的数据集，建立了后面research的benchmarks。</p>
<h3 id="Models"><a href="#Models" class="headerlink" title="Models"></a><center><strong>Models</strong></center></h3><p>模型包含encoder和decoder，encoder是一个bidirectional GRU-RNN，而decoder是一个跟encoder有着相同大小hidden-state size的uni-directional GRU-RNN；在source-hidden states之间是<code>attention mechanism</code>，最终由一个<code>soft-max layer</code>为目标词汇生成单词。文章的model有如下三个改进的方面：</p>
<ol>
<li>Feature-rich encoder;</li>
<li>Switching generator-pointer model;</li>
<li>Hierarchical attention model.</li>
</ol>
<p>第一个改进，为encoder的输入增加新的features，比如parts-of-speech tags, named-entity tags (NER tags),和离散后的TF以及IDF数据。</p>
<p>第二个改进，为decoder增加一个<code>switch</code>，决定用generator还是用一个指针指向文档当中的某一个位置。如果switch打开，则模型还是用以前的方法从目标词库当中生成单词；如果关闭的话，则生成一个指针指向源的某一个位置，这个位置的word就会被添加到summary当中。每一个<code>time step</code>，<code>Switch</code>被定义为基于linear layer的sigmoid函数，如下：<br>$$<br>P(s_i=1)=\sigma(\mathbf{v}^s\cdot(\mathbf{W}_h^sh_i)+\mathbf{W}_e^s\mathbf{E}[o_{i-1}]+\mathbf{W}_c^s\mathbf{c}_i+\mathbf{b}^s)),<br>$$<br>其中$P(s_i=1)$表示在第$i$个time step开关被打开的概率，$\mathbf{c}_i$是attention-weighted context vector，$<br>mathbf{W}_h^s, \mathbf{W}_e^s，\mathbf{W}_c^s, \mathbf{b}^s$和$\mathbf{v}_s$都是开关的参数。<mark>这个是不是就相当于CNN中的<code>filters</code>的概念。</mark>改进后的模型图如下图所示。</p>
<center><img src="/img/daily/arxiv08101.png" width="70%"></center>

<p>第三个改进，在encoder采用<mark>两层</mark>概念，即word level和sentence level。Attention mechanism同时作用在这两层上，即<code>word-level</code>的attention被相应的<code>sentence-level</code>的attention重新校正，定义如下：<br>$$<br>P^a(j) = \frac{P_w^a(j)P_s^a(s(j))}{\sum_{k=1}^{N_d}P_w^a(k)P_s^a(s(k))}，<br>$$<br>其中，$P_w^a(j)$是word-level第j个位置的attention weight，$P_s^a(l)$是原文件中第l个位置sentence-level的attention weight。得到的re-scaled attention被用来计算decoder的hidden state的输入（attention-weighted context vector）。而且，将positional embeddings加到sentence-level RNN的hidden state，来表示文档中句子的位置重要性。这个模型因此能够将关键句子跟关键词联系在一起。</p>
<center><img src="/img/daily/arxiv08102.png" width="70%"></center>

<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a><center><strong>Experiments</strong></center></h3><p>分了好几个实验，比较感兴趣的实验是在CNN/Daily Mail上的实验，实验比较了三个模型，实验结果如图所示。最后一个模型”temp”表示<code>Temporal Attention Model</code>，<mark>解决了entity重复出现的问题，这个可以用在tag identification上面</mark>。另外，感觉这个<code>Temporal Attention Model</code>跟LSTM类似，只不过是在attention上的LSTM。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><center><strong>Reference</strong></center></h3><p>[1] <a href="https://aclweb.org/anthology/K/K16/K16-1028.pdf" target="_blank" rel="external">Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond</a></p>

            <blockquote>
                <p>
                Permalink：
                <a href="http://cuiyungao.github.io/2016/08/16/arxiv0810/" target="_blank" rel="external">http://cuiyungao.github.io/2016/08/16/arxiv0810/</a>
                </p>
                <footer><cite><a href="http://cuiyungao.github.io">@Cuiyun Gao's Daily Digest</a></cite></footer>
            </blockquote>
            </div>
            
<nav class="post-nav">
  
    <div class="waves-block waves-effect prev fl">
      <a href="/2016/08/17/CAS/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">Consensus Attention-based Neural Networks for Chinese Reading Comprehension</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next fr">
      <a href="/2016/08/16/enrich/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">Enriching Word Vectors with Subword information</h4>
      </a>
    </div>
  
</nav>


            
            
<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="arxiv0810" data-title="Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond" data-url="http://cuiyungao.github.io/2016/08/16/arxiv0810/index.html"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"cuiyungao"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>





        </div>
    </div>
</article>
    </div>
  </main>
<div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>


<script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>

<script src="/js/main.js"></script>



<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<script type="text/template" id="search-tpl">
<li class="item">
    <a href="/{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</script>

<script src="/js/search.js"></script>



<! -- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->








</body>
</html>
