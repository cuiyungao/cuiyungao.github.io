<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.5.0/styles/default.min.css">
<script src="http://code.jquery.com/jquery-2.2.4.min.js"  integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="   crossorigin="anonymous"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.5.0/highlight.min.js"></script>
<script src="/js/SimpleCore.js" type="text/javascript"></script>
<!--[if lte IE 9]><meta http-equiv="refresh" content="0;url=/warn.html"><![endif]-->

<title>User Modeling with Neural Network for Review Rating Prediction</title>
<meta name="author" content="Cuiyun Gao">

<meta name="keywords" content="undefined">

<meta name="description " content="null">

<link rel="icon" href="/images/favicon.png">

<link rel="stylesheet" href="/css/style.css">

  </head>
  <body>
    <aside id="sidebar">
  <nav id="tags">
    <a href="http://shuoit.net" id="avatar" style="background-image:url(/images/favicon.png)"></a>
    <ul id="tags__ul">
      <li id="pl__all" class="tags__li tags-btn active">所有文章</li>
      
      <li id="daily" class="tags__li tags-btn">daily</li>
      
      <li id="papers" class="tags__li tags-btn">papers</li>
      
    </ul>
    <div id="tags__bottom">
      <a href="http://github.com/tangkunyin" rel="nofollow" id="icon-github" target="_blank" class="tags-btn fontello"></a>
      <a href="http://shang.qq.com/wpa/qunwpa?idkey=6dc2741479cd031cc533fe5080081df44d0f9d95bc5083e8e1244c92f4aae218" rel="nofollow" id="icon-qq" target="_blank" class="tags-btn fontello"></a>
    </div>
  </nav> <!-- end #tags -->
  <div id="posts-list">
    <form action="#" id="search-form" target="_blank">
      <a href="/" id="mobile-avatar" style="background-image:url(/images/favicon.png)"></a>
      <input id="search-input" type="text" placeholder="戳一下不会怀孕" />
    </form>
    <nav id="pl__container">
      
            
                <a class="daily pl__all" href="/2016/06/29/UFLDL/" title="UFLDL Tutorial">
                  <span class="pl__circle"></span><span class="pl__title">UFLDL Tutorial</span><span class="pl__date">2016-06-29</span>
                </a>
            
                <a class="daily pl__all" href="/2016/06/29/cf/" title="Collaborative Filtering (CF)">
                  <span class="pl__circle"></span><span class="pl__title">Collaborative Filtering (CF)</span><span class="pl__date">2016-06-29</span>
                </a>
            
                <a class="daily pl__all" href="/2016/06/28/code/" title="Useful Source Code for NLP">
                  <span class="pl__circle"></span><span class="pl__title">Useful Source Code for NLP</span><span class="pl__date">2016-06-28</span>
                </a>
            
                <a class="daily pl__all" href="/2016/06/28/crawler/" title="Data Crawling">
                  <span class="pl__circle"></span><span class="pl__title">Data Crawling</span><span class="pl__date">2016-06-28</span>
                </a>
            
                <a class="daily pl__all" href="/2016/06/27/diveTensorflow/" title="Dive into TensorFlow">
                  <span class="pl__circle"></span><span class="pl__title">Dive into TensorFlow</span><span class="pl__date">2016-06-27</span>
                </a>
            
                <a class="daily pl__all" href="/2016/06/29/goodturing/" title="Good-Turing Estimation 大数据处理平滑算法">
                  <span class="pl__circle"></span><span class="pl__title">Good-Turing Estimation 大数据处理平滑算法</span><span class="pl__date">2016-06-29</span>
                </a>
            
                <a class="daily pl__all" href="/2016/06/27/howtoread/" title="How to read:character level deep learning">
                  <span class="pl__circle"></span><span class="pl__title">How to read:character level deep learning</span><span class="pl__date">2016-06-27</span>
                </a>
            
                <a class="daily pl__all" href="/2016/06/28/lda/" title="LDA Understanding">
                  <span class="pl__circle"></span><span class="pl__title">LDA Understanding</span><span class="pl__date">2016-06-28</span>
                </a>
            
                <a class="daily pl__all" href="/2016/06/28/material/" title="Study Material for Deep Learning and NLP">
                  <span class="pl__circle"></span><span class="pl__title">Study Material for Deep Learning and NLP</span><span class="pl__date">2016-06-28</span>
                </a>
            
                <a class="daily pl__all" href="/2016/07/04/memory-network/" title="Three Impactful ML Topics at ICML&#39;16">
                  <span class="pl__circle"></span><span class="pl__title">Three Impactful ML Topics at ICML&#39;16</span><span class="pl__date">2016-07-04</span>
                </a>
            
                <a class="daily pl__all" href="/2016/06/28/memorization/" title="Memorization and Exploration in Recurrent Neural Language Models">
                  <span class="pl__circle"></span><span class="pl__title">Memorization and Exploration in Recurrent Neural Language Models</span><span class="pl__date">2016-06-28</span>
                </a>
            
                <a class="daily pl__all" href="/2016/07/04/researcher/" title="Find Researchers Here">
                  <span class="pl__circle"></span><span class="pl__title">Find Researchers Here</span><span class="pl__date">2016-07-04</span>
                </a>
            
                <a class="daily pl__all" href="/2016/06/27/nlpcourses/" title="Courses for NLP and Deep Learning">
                  <span class="pl__circle"></span><span class="pl__title">Courses for NLP and Deep Learning</span><span class="pl__date">2016-06-27</span>
                </a>
            
      
            
                <a class="papers pl__all" href="/2016/06/28/acl16/" title="Generative Topic Embedding:a Continuous Representation of Documents">
                  <span class="pl__circle"></span><span class="pl__title">Generative Topic Embedding:a Continuous Representation of Documents</span><span class="pl__date">2016-06-28</span>
                </a>
            
                <a class="papers pl__all" href="/2016/06/26/SPINN/" title="SPINN">
                  <span class="pl__circle"></span><span class="pl__title">SPINN</span><span class="pl__date">2016-06-26</span>
                </a>
            
                <a class="papers pl__all" href="/2016/06/28/drnn/" title="Deep Recursive Neural Networks for Compositionality in Language">
                  <span class="pl__circle"></span><span class="pl__title">Deep Recursive Neural Networks for Compositionality in Language</span><span class="pl__date">2016-06-28</span>
                </a>
            
                <a class="papers pl__all" href="/2016/06/30/usermodeling/" title="User Modeling with Neural Network for Review Rating Prediction">
                  <span class="pl__circle"></span><span class="pl__title">User Modeling with Neural Network for Review Rating Prediction</span><span class="pl__date">2016-06-30</span>
                </a>
            
                <a class="papers pl__all" href="/2016/06/30/predictingamazon/" title="Predicting Amazon Ratings Using Neural Networks">
                  <span class="pl__circle"></span><span class="pl__title">Predicting Amazon Ratings Using Neural Networks</span><span class="pl__date">2016-06-30</span>
                </a>
            
      
    </nav>
  </div> <!-- end #posts-list -->
</aside> <!-- end #sidebar -->

    <div id="post">
      <div id="pjax">
        <article id="post__content">
  <h1 id="post__title" data-identifier="2016-06-30">User Modeling with Neural Network for Review Rating Prediction</h1>
  <p>[IJCAI’15] User Modeling with Neural Network for Review Rating Prediction. <a href="http://ir.hit.edu.cn/~dytang/" target="_blank" rel="external">Duyu Tang</a>, Bing Qin, Ting Liu<br>Proceeding of The 24th International Joint Conference on Artificial Intelligence.</p>
<a id="more"></a>
<p>作者Duyu Tang的分析集中于sentiment analysis，一年发了很多NLP的顶会文章（EMNLP, ACL, IJCAI, etc.）。</p>
<p>本文通过考虑user information来改善review rating prediction。启发源于lexical composition model，将<code>compositional modifier</code>作为一个matrix, 用<code>matrix-vector mulplication</code>作为compositon function。本文延伸lexical semantic compositio models，建立了<code>user-word composition vector model</code> (UWCVM)，并将结果作为feature用supervised learning framework来进行review rating prediction。</p>
<h3 id="Problem-Definition"><a href="#Problem-Definition" class="headerlink" title="Problem Definition"></a><center><strong>Problem Definition</strong></center></h3><p>Review rating prediction可以看做是a classificaiton/regression problem，由Pang and Lee <a href="http://www.cs.cornell.edu/home/llee/papers/pang-lee-stars.pdf" target="_blank" rel="external">2005</a>最开始做，采用<code>metric labeling</code> framework。Rating的performance很大程度上依赖于<code>feature representation</code>的选择。</p>
<p>Problem: Given a review $r_{k_j}$ comprised of $n$ words $\{w_1,w_2,…,w_n\}$ written by user $u_k$ as input, review rating prediction aims at infering the numeric rating (1~4 or 1~5 stars) of $r_{k_j}$. The problem can be regarded as a multi-class classification problem by inferring a discrete rating score.</p>
<h3 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a><center><strong>Methodology</strong></center></h3><p>The method includes two <code>composition models</code>, the user-word composition vector model (<strong>DWCVM</strong>) and the document composition vector model (<strong>DCVM</strong>). The former model将原始的word vectors加入user information，the latter model则将modified word vectors转化成review representation，并用其作为feature来进行rating prediction。Training的过程采用Pang and Lee提出的<code>supervised metric labeling</code>的方法。整个过程如下图表示：<br><br></p>
<center><img src="/img/papers/usermodeling.png" width="50%"></center>

<h4 id="User-Word-Composition-Vector-Model"><a href="#User-Word-Composition-Vector-Model" class="headerlink" title="User-Word Composition Vector Model"></a>User-Word Composition Vector Model</h4><p>整个model将original word vectors融入user information。融入的方法有两种：<code>additive</code>和<code>multiplicative</code>。给定两个向量$v_1$和$v_2$，<strong>Additive</strong>的结合方式认为输出向量$p$是a linear function of Cartesian product of $v_1$ and $v_2$，如下：</p>
<p>$$<br>p = \mathbf{A}\times v_1 + \mathbf{B}\times v_2<br>$$<br>其中$\mathbf{A}$和$\mathbf{B}$是matrices parameters，用来encode $v_1$, $v_2$对$p$的贡献。<strong>Multiplicative</strong>的结合方式认为输出向量$p$是a linear function of the tensor product of $v_1$ and $v_2$，如下：</p>
<p>$$<br>p = \mathbf{T}\times v_1 \times v_2 = \mathbf{U}_1 \times v_2<br>$$<br>其中$\mathbf{T}$是一个rank为3的tensor，将$v_1,v_2$的tensor product映射到$p$上。$\mathbf{T}$和$\v_1$的Partial product可以被看做生成新的矩阵$\mathbf{U}_1$，这个矩阵可以modify原始的word vectors。这两种结合方式可以用下图表示：<br><br></p>
<center><img src="/img/papers/usermodeling2.png" width="50%"></center>

<p>文章选用<code>multiplicative composition</code>，因为这种结合方式符合最初的用user information来改善word vectors的想法。后面的实验也验证了multiplicative composition的结合方式准确率要高于additive composition。</p>
<p>为了减少parameter size，user representation被用low-rank plus diagonal approximation来表示：$\mathbf{U}_k=\mathbf{U}_{k1} \times \mathbf{U}_{k2} + diag(u^{\prime})$，其中$\mathbf{U}_{k1}\in \mathbb{R}^{d\times r}$, $\mathbf{U}_{k2}\in \mathbb{R}^{r\times d}$, $u^{\prime}\in \mathbb{R}^d$。$u^{\prime}$是每个user共享的background representation，以应对某些在test set中有而在training set中没有的users，即<code>Out-Of-Vocabulary</code> situation。最终modified word vectors $p_i$：</p>
<p>$$<br>p_i = tanh(\mathbf{e}_{ik}) = tanh(\mathbf{U}_k\times \mathbf{e}_i)<br>\; = tanh((\mathbf{U}_{k1}\times \mathbf{U}_{k2} + diag(u^{\prime})) \times \mathbf{e}_i)<br>$$</p>
<h4 id="Document-Composition-Vector-Model"><a href="#Document-Composition-Vector-Model" class="headerlink" title="Document Composition Vector Model"></a>Document Composition Vector Model</h4><p>文中采用一个简单而有效的方法<a href="http://anthology.aclweb.org/P/P14/P14-1006.pdf" target="_blank" rel="external">paper</a>, recursivley uses <code>biTanh</code> function来生成document representation:</p>
<p>$$<br>biTanh(p) = \sum_{i=1}^n tanh(p_{i-1} + p_i)<br>$$<br>Each sentence将user-modified word vectors作为输入，得到sentence vectors；然后再将sentence vectors输入到<code>biTanh</code>得到最终的document vector $vec(doc)$。<code>biTanh</code>的Recursive use可以看做是two pairs of bag-of-word convolutional neural network，其中window size是2，parameters通过<code>addition</code>和<code>tanh</code>来定义。</p>
<h4 id="Rating-Prediction-with-Metric-Labeling"><a href="#Rating-Prediction-with-Metric-Labeling" class="headerlink" title="Rating Prediction with Metric Labeling"></a>Rating Prediction with Metric Labeling</h4><p>Review representation被用来进行review rating prediction，方法是<code>metric labeling</code> framework。</p>
<h4 id="Model-Training"><a href="#Model-Training" class="headerlink" title="Model Training"></a>Model Training</h4><p>获取back-propagation中对于whole set of parameters的derivative of the loss, 然后用stochastic gradient descent with mini-batch来更新这些parameters。文中用<code>dropout</code>来避免neural network being over-fitting。</p>
<p><strong>Note:</strong> Cases that rating does not match with review texts is not considered. [Zhang et al., SIGIR’14]  <a href="http://dl.acm.org/citation.cfm?id=2609501" target="_blank" rel="external">Paper</a></p>
<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a><center><strong>Experiment</strong></center></h3><p>实验数据集有两个：<code>Yelp13</code>和<code>RT05</code>。实验结果说明:</p>
<ul>
<li>Semantic composition可以提高预测的准确度，并且结合<span style="color:white">metric labeling</span>可以改善结果，因为它基于”similar items, similar labels”的idea。</li>
<li>一个用户有越多的reviews，则这个用户的rating可以被很好地估计。</li>
<li>SSPE [Tang et al., 2014a]  <a href="http://anthology.aclweb.org/C/C14/C14-1018.pdf" target="_blank" rel="external">paper</a>更适用于short review.</li>
</ul>

</article>
<button id="js-fullscreen"><span id="icon-arrow" class="fontello"></span></button>

  <div id="post__action">
      <a id="icon-heart" class="fontello" href="javascript:donate();"></a>
  </div>
  <script src="/layer/layer.js" type="text/javascript"></script>
  <script src="/layer/extend/layer.ext.js" type="text/javascript"></script>


<!-- 多说评论框 start -->
<div class="ds-thread" data-thread-key="undefined" data-title="User Modeling with Neural Network for Review Rating Prediction" data-url="http://shuoit.net/2016/06/30/usermodeling/"></div>
<!-- 多说评论框 end -->
<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"shuoit"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0]
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- 多说公共JS代码 end -->

        <p id="copyright">由<a href="http://hexo.io" target="_blank">Hexo</a>创建&nbsp;&nbsp;|&nbsp;&nbsp;主题<a href="https://github.com/tangkunyin/hexo-theme-simple" target="_blank">Simple</a>&nbsp;&nbsp;|&nbsp;&nbsp;感谢<a href="https://coding.net/register?key=bcace447-fa41-4579-9783-86fdf0f723e2" target="_blank">Coding</a>提供强力驱动</p>
<!-- 百度统计 -->
<script>
  var _hmt = _hmt || [];
  (function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?a01595b492af7e4a793230e3d49ae638";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
  })();
</script>

      </div>
      <div id="post__toc-trigger">
        <div id="post__toc">
          <span id="post__toc-title">目录</span>
          <ul id="post__toc-ul"></ul>
        </div>
      </div>
    </div>
  </body>
</html>
