<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Deep Recursive Neural Networks for Compositionality in Language | Cuiyun Gao&#39;s Daily Digest | Work Hard, and Play Harder. 如果有一天：你不再寻找爱情，只是去爱；你不再渴望成功，只是去做；你不再追求成长，只是去修行；一切才真正开始~！</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="theme-color" content="#3F51B5">
  
  
  <meta name="keywords" content="NLP,Deep Learning">
  <meta name="description" content="Irsoy, Ozan, and Claire Cardie. “Deep recursive neural networks for compositionality in language.” Advances in Neural Information Processing Systems. 2014.">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep Recursive Neural Networks for Compositionality in Language">
<meta property="og:url" content="http://cuiyungao.github.io/2016/06/28/drnn/index.html">
<meta property="og:site_name" content="Cuiyun Gao's Daily Digest">
<meta property="og:description" content="Irsoy, Ozan, and Claire Cardie. “Deep recursive neural networks for compositionality in language.” Advances in Neural Information Processing Systems. 2014.">
<meta property="og:image" content="http://cuiyungao.github.io/img/papers/drnn.png">
<meta property="og:image" content="http://cuiyungao.github.io/img/papers/drnnformula.png">
<meta property="og:image" content="http://cuiyungao.github.io/img/papers/drnnfig2.png">
<meta property="og:image" content="http://cuiyungao.github.io/img/papers/drnnformula2.png">
<meta property="og:image" content="http://cuiyungao.github.io/img/papers/drnnresult1.png">
<meta property="og:image" content="http://cuiyungao.github.io/img/papers/drnnresult2.png">
<meta property="og:updated_time" content="2016-08-21T09:23:40.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deep Recursive Neural Networks for Compositionality in Language">
<meta name="twitter:description" content="Irsoy, Ozan, and Claire Cardie. “Deep recursive neural networks for compositionality in language.” Advances in Neural Information Processing Systems. 2014.">
<meta name="twitter:image" content="http://cuiyungao.github.io/img/papers/drnn.png">
  
    <link rel="alternative" href="/atom.xml" title="Cuiyun Gao&#39;s Daily Digest" type="application/atom+xml">
  
  <meta name="summary" content="&lt;p&gt;Irsoy, Ozan, and Claire Cardie. “Deep recursive neural networks for compositionality in language.” Advances in Neural Information Processing Systems. 2014.&lt;/p&gt;">
  <link rel="shortcut icon" href="/img/favicon.png">
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="loading" class="active"></div>

  <nav id="menu" class="hide" >
   <div class="inner flex-row-vertical">
  <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
      <i class="icon icon-lg icon-close"></i>
  </a>
  <div class="brand-wrap">
    <div class="brand">
      <a href="/" class="avatar"><img src="/img/head.jpg"></a>
      <hgroup class="introduce">
        <h5 class="nickname">Cuiyun Gao</h5>
        <a href="mailto:undefined" title="cygao@cse.cuhk.edu.hk" class="mail">cygao@cse.cuhk.edu.hk</a>
      </hgroup>
    </div>
  </div>
  <ul class="nav flex-col">
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-My Home"></i>
            My Home
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-Paper Reading"></i>
            Paper Reading
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-Daily Digest"></i>
            Daily Digest
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-My Works"></i>
            My Works
          </a>
        </li>
    
        <li class="waves-block waves-effect">
          <a href="/"  >
            <i class="icon icon-lg icon-About Me"></i>
            About Me
          </a>
        </li>
    
  </ul>

  <footer class="footer">
  <p><a rel="license" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0;vertical-align:middle;" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAAAPCAMAAABEF7i9AAAAllBMVEUAAAD///+rsapERER3d3eIiIjMzMzu7u4iIiKUmZO6v7rKzsoODg4RERFVVVUNDQ0NDg0PEA8zMzNLTEtbXltmZmZydnF9gn2AgICPkI+ZmZmqqqq7u7vFxsXIzMgNDQwZGRkgICAhISEkJSMnKCcuMC4xMzE5Ozk7PTtBQkFCQkJDQ0Nna2eGhoaHh4ezuLLGysbd3d1wVGpAAAAA4UlEQVR42q2T1xqCMAyFk7QsBQeKA9x7j/d/OSm22CpX0nzcpA1/T05aAOuBVkMAScQFHLnEwoCo2f1TnQIGoVMewjZEjVFN4GH1Ue1Cn2jWqwfsOOj6wDwGvotsl/c8lv7KIq1eLOsT0HMFHMIE/RZyHnlphryT9zyV+8WH5e8yQw3wnQvgAFxPTKUVi555SHR/lOfLMgVTeDlSfN+TaoUsiTyeIm+bCkHvCA2FUKG48LDtYBZBknsYP/G8NTw0gaaHyuQf4H5pecrB/FYCT2sL9zAfy1Xyjou6L8X2W7YcLyBZCRtnq/zfAAAAAElFTkSuQmCC" /></a></p>
  <p>Cuiyun Gao&#39;s Daily Digest &copy; 2016</p>
  <p>Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme
  <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a></p>
  <a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-2x icon-rss-square"></i></a>
</footer>

</div>

  </nav>
  <main id="main">
    <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Deep Recursive Neural Networks for Compositionality in Language</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input " autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
    </div>
</header>
<header class="content-header">
  <div class="container">
    <h1 class="author">Deep Recursive Neural Networks for Compositionality in Language</h1>
    <h5 class="subtitle">
        
            <time datetime="2016-06-28T07:04:35.000Z" itemprop="datePublished" class="page-time">
  2016-06-28
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/papers/">papers</a></li></ul>

        
    </h5>
  </div>
</header>

    <div class="container body-wrap">
      <article id="post-drnn" 
  class="article article-type-post" itemprop="blogPost">
    <div class="post-meat flex-row">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li></ul>

    </div>
    <div class="post-body">
        <aside class="post-widget" id="post-widget">

            

            
            <nav class="post-toc-wrap" id="post-toc">
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Recursive-Neural-Network"><span class="post-toc-text">Recursive Neural Network</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Recurrent-v-s-Recursive"><span class="post-toc-text">Recurrent v.s. Recursive</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Deep-Recursive-Neural-Networks"><span class="post-toc-text">Deep Recursive Neural Networks</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Results"><span class="post-toc-text">Results</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Result-1"><span class="post-toc-text">Result 1</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Result-2"><span class="post-toc-text">Result 2</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Reference"><span class="post-toc-text">Reference</span></a></li></ol>
            </nav>
            
        </aside>

        <div class="post-main">

            <div class="post-content" id="post-content" itemprop="postContent">
            <p>Irsoy, Ozan, and Claire Cardie. “Deep recursive neural networks for compositionality in language.” Advances in Neural Information Processing Systems. 2014.</p>
<a id="more"></a>
<h3 id="Recursive-Neural-Network"><a href="#Recursive-Neural-Network" class="headerlink" title="Recursive Neural Network"></a><center><strong>Recursive Neural Network</strong></center></h3><p>Recursive neural networks (RNNs) comprise a class of architecture that can operate on <code>structured input</code>. <span style="color:white">The same set of weights is recursively applied within a structural setting.</span> Given a positional directed acyclic graph, it visits the nodes in topological order, and recursively applies transformations to generate further representations from previously computed representations of children.</p>
<p>A <code>recurrent neural network</code> is simply a <code>recursive</code> neural network with a particular structure (Figure 1c).<br><br></p>
<center><img src="/img/papers/drnn.png" width="60%"></center>

<p><span style="color:red">Problem:</span> Even though RNNs are deep in structure, they lack the capacity for hierarchical representation that exists in conventional deep feed-forward networks and recurrent neural networks.</p>
<h3 id="Recurrent-v-s-Recursive"><a href="#Recurrent-v-s-Recursive" class="headerlink" title="Recurrent v.s. Recursive"></a><center><strong>Recurrent v.s. Recursive</strong></center></h3><p>Recurrent neural networks are deep in time, while recursive neural networks are deep in structure (due to the repeated application of recursive connections). Recently, the notions of depth in time - the result of recurrent connections, and depth in space - the result of stacking multiple layers on top of one another, are distinguished for recurrent neural network. Deep recurrent neural networks were proposed for composing these concepts. They are created by stacking multiple recurrent layers on top of each other. This allows the extra notion of depth to be incorporated into temporal processing.</p>
<p>Inspired by <code>deep recurrent</code> neural networks, <code>deep recursive</code> neural networks are proposed in this paper.</p>
<h3 id="Deep-Recursive-Neural-Networks"><a href="#Deep-Recursive-Neural-Networks" class="headerlink" title="Deep Recursive Neural Networks"></a><center><strong>Deep Recursive Neural Networks</strong></center></h3><p>An important benefit of depth is the hierarchy among <code>hidden representations</code>: every hidden layer conceptually lies in a different representation space and potentially is a more abstract representation of the input than the previous layer.</p>
<p>The DRNN is constructed by <code>stacking</code> multiple layers of individual <code>recursive</code> nets:<br><br></p>
<center><img src="/img/papers/drnnformula.png" width="50%"></center>

<p>where $i$ means the multiple stacked layers, $W_L^{(i)}$, $W_R^{(i)}$, and $b^{(i)}$ are the weight matrices that connect the left and right children to the parent, and a bias vector, respectively. $V^{(i)}$ is the weight matrix that connects the $(i-1)$th hidden layer to the $i$th hidden layer. For the untying shown in Figure 1b, every node is represented in the same space above the first, regardless of their <code>leafness</code>. Figure 2 shows the weights that are untied or shared.<br><br></p>
<center><img src="/img/papers/drnnfig2.png" width="60%"></center>

<p>For <code>prediction</code>, we connect the output layer to <span style="color: red">only</span> the <code>final hidden layer</code>.<br><br></p>
<center><img src="/img/papers/drnnformula2.png" width="20%"></center>

<p>If we connect the output layer to all hidden layers, multiple hidden layers can have <code>synergistic effects</code> on the output and make it more difficult to qualitatively analyze each layer.</p>
<h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a><center><strong>Results</strong></center></h3><p><span style="color:white">Data:</span> Stanford Sentiment Treebank (SST) <a href="http://nlp.stanford.edu/pubs/SocherEtAl_EMNLP2013.pdf" target="_blank" rel="external">link</a></p>
<h4 id="Result-1"><a href="#Result-1" class="headerlink" title="Result 1"></a>Result 1</h4><p>Comparing with multiplicative RNN and the more recent Paragraph Vectors, DRNNs outperform their shallow counterparts of the same size. Deep RNN outperforms the baselines, achieving <code>state-of-the-art</code> performance on the task.<br><br></p>
<center><img src="/img/papers/drnnresult1.png" width="60%"></center>

<p><span style="color: red">Reason:</span> The authors attribute an important contribution of the improvement to <code>dropouts</code>.</p>
<h4 id="Result-2"><a href="#Result-2" class="headerlink" title="Result 2"></a>Result 2</h4><p>For searching <code>nearest neighbor phrases</code>, different layers capture different aspects. <code>One-nor</code> distance mearsure is used.<br><br></p>
<center><img src="/img/papers/drnnresult2.png" width="60%"></center>

<p><span style="color: red">Analysis:</span> The first layer is dominated by one of the words that is composed. The seconde layer takes syntactic similarity more into account. The third layer captures the sentiment.</p>
<p><span style="color: red">Inspiration:</span> Can we apply this into emoji detection?<br><br><br>Paper can be download <a href="https://www.cs.cornell.edu/~oirsoy/files/nips14drsv.pdf" target="_blank" rel="external">here</a>.<br>Code is written in C++, can be found <a href="https://github.com/oir/deep-recursive" target="_blank" rel="external">here</a>.<br>Introduction webpage is <a href="http://www.cs.cornell.edu/~oirsoy/drsv.htm" target="_blank" rel="external">here</a>.</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><center><strong>Reference</strong></center></h3><p>[1] <a href="http://mp.weixin.qq.com/s?__biz=MzI1NTE4NTUwOQ==&amp;mid=2650325311&amp;idx=1&amp;sn=fa4cedfffe6cd0ecd0158fd60ad5d95d#rd" target="_blank" rel="external">递归神经网络(Recurrent Neural Network)学习</a>.里面介绍了RNN的最新论文以及常用的一些比较成功的tricks。</p>

            <blockquote>
                <p>
                Permalink：
                <a href="http://cuiyungao.github.io/2016/06/28/drnn/" target="_blank" rel="external">http://cuiyungao.github.io/2016/06/28/drnn/</a>
                </p>
                <footer><cite><a href="http://cuiyungao.github.io">@Cuiyun Gao's Daily Digest</a></cite></footer>
            </blockquote>
            </div>
            
<nav class="post-nav">
  
    <div class="waves-block waves-effect prev fl">
      <a href="/2016/06/28/lda/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">LDA Understanding</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next fr">
      <a href="/2016/06/27/howtoread/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">How to read:character level deep learning</h4>
      </a>
    </div>
  
</nav>


            
            
<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="drnn" data-title="Deep Recursive Neural Networks for Compositionality in Language" data-url="http://cuiyungao.github.io/2016/06/28/drnn/index.html"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"cuiyungao"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>





        </div>
    </div>
</article>
    </div>
  </main>
<div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>


<script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>

<script src="/js/main.js"></script>



<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<script type="text/template" id="search-tpl">
<li class="item">
    <a href="/{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</script>

<script src="/js/search.js"></script>



<! -- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->








</body>
</html>
