<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Cuiyun Gao&#39;s Daily Digest</title>
  <subtitle>Work Hard, and Play Harder. 如果有一天：你不再寻找爱情，只是去爱；你不再渴望成功，只是去做；你不再追求成长，只是去修行；一切才真正开始~！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://cuiyungao.github.io/"/>
  <updated>2016-12-05T14:28:27.000Z</updated>
  <id>http://cuiyungao.github.io/</id>
  
  <author>
    <name>Cuiyun Gao</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>topic2vec</title>
    <link href="http://cuiyungao.github.io/2016/12/05/topic2vec/"/>
    <id>http://cuiyungao.github.io/2016/12/05/topic2vec/</id>
    <published>2016-12-05T14:28:27.000Z</published>
    <updated>2016-12-05T14:28:27.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Adversarial Training Methods for Semi-Supervised Text Classification</title>
    <link href="http://cuiyungao.github.io/2016/11/15/adversarial/"/>
    <id>http://cuiyungao.github.io/2016/11/15/adversarial/</id>
    <published>2016-11-15T09:41:30.000Z</published>
    <updated>2016-11-15T13:51:57.000Z</updated>
    
    <content type="html"><![CDATA[<p>Submitted to ICLR’17, Google Brain, Kyoto University和OpenAI的合作，作者Takeru Miyato, Andrew M. Dai, Ian Goodfellow。</p>
<a id="more"></a>
<p>Adversarial training和virtual adversarial training都需要对输入的数字形式做小的perturbation，不适用于高维稀疏输入，比如one-hot word representations。文章扩展图像领域流行的这两种方法到文本领域，对word embedding进行perturbation来作为LSTM的输入，而不是原本的输入向量。可以把这两种方法看做是正则化的方法，为输入加入噪声，可以实现semi-supervised的任务。</p>
<p>优势在于，传统的word embedding被语法结构影响，即使两个完全相反的词（比如”good”和”bad”）在表示形式上也是相近的，没有表示出词本身的意思。Adversarial training能够保证小的改变不能使句子的意思相反，所以有着相近语法结构但是不同意义的词能够被分开，可以用来做情感分类和sequence model等。</p>
<h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a><center><strong>Methods</strong></center></h3><p>Perturbation是有界的，大的norm很容易使perturbations不明显，所以model的输入（word embeddings）首先被normalized，如下所示：</p>
<p>$$<br>\bar{\mathbf{v}}_k = \frac{\mathbf{v}_k-E(\mathbf{v})}{\sqrt{Var(\mathbf{v})}}，<br>$$<br>其中，$E(\mathbf{v})=\sum^{K}_{j=1} f_j\mathbf{v}_j$，$Var(\mathbf{v}) = \sum^K_{j=1} f_j(\mathbf{v}_j-E(\mathbf{v}))^2$，$f_i$是第$i$个词在所有训练集中出现的频率。</p>
<p>以adversarial training为例，文章对word embeddings进行adversarial perturbation，而不是直接应用在输入上。假设normalized之后的输入序列为$\mathbf{s}$，即$[\bar{\mathbf{v}}^{(1)}, \bar{\mathbf{v}}^{(2)}, \ldots, \bar{\mathbf{v}}^{(T)}]$，给定$\mathbf{s}$，$y$的条件概率为$p(y|\mathbf{s;\theta})$，其中$\mathbf{\theta}$为模型参数，则$\mathbf{s}$上的adversarial perturbation $\mathbf{r}_{adv}$为：</p>
<p>$$<br>\mathbf{r} = -\epsilon \mathbf{g}/||\mathbf{g}||_2, where\; \mathbf{g}=\bigtriangledown_s log p(y|\mathbf{s;\hat{\theta}}).<br>$$</p>
<p>应用在LSTM上，如下图(b)所示。定义其adversarial loss如下：</p>
<center><img src="/img/papers/adversarial1.png" width="100%"></center>

<p>$$<br>L_{adv}(\mathbf{\theta})=-\frac{1}{N}\sum^N_{n=1} log p(y_n | \mathbf{s}_n + \mathbf{r}_{adv,n}; \mathbf{\theta})，<br>$$<br>其中$N$为labeled的例子的数目。通过随机梯度下降来进行training。</p>
<p>文章也提供了virtual adversarial training的方法。</p>
<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a><center><strong>Experiment</strong></center></h3><p>文本预处理：去掉仅在一个doc中出现的words，并且去掉了stop words。Word embedding为rnn pretraining的结果。Baseline为仅仅pretraining和embedding dropout的方法。实验数据集有5个，<a href="http://ai.stanford.edu/~amaas/data/sentiment/" target="_blank" rel="external">IMDB</a>，<a href="http://riejohnson.com/cnn_data.html" target="_blank" rel="external">Elec</a>，<a href="http://snap.stanford.edu/data/web-Amazon.html" target="_blank" rel="external">Rotten Tomatoes</a>，DBpedia和RCV1。实验结果发现virtual adversarial training和adversarial training相比对输入随意增加噪声和已有的state-of-the-art的方法(e.g., SA-LSTM, one-hot bi-LSTM, 以及paragraph vectors)有较低的negative log-likelihood；word embedding的效果好，考虑到词的语法结构和词义；在词的分类效果上也优于已有的最佳方法。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><center><strong>Reference</strong></center></h3><p><a href="https://arxiv.org/abs/1605.07725" target="_blank" rel="external">Adversarial Training Methods for Semi-Supervised Text Classification</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Submitted to ICLR’17, Google Brain, Kyoto University和OpenAI的合作，作者Takeru Miyato, Andrew M. Dai, Ian Goodfellow。&lt;/p&gt;
    
    </summary>
    
      <category term="papers" scheme="http://cuiyungao.github.io/categories/papers/"/>
    
    
      <category term="ICLR" scheme="http://cuiyungao.github.io/tags/ICLR/"/>
    
      <category term="Text Classification" scheme="http://cuiyungao.github.io/tags/Text-Classification/"/>
    
      <category term="Adversarial Training" scheme="http://cuiyungao.github.io/tags/Adversarial-Training/"/>
    
  </entry>
  
  <entry>
    <title>Causal Impact Analysis for App Releases in Google Play</title>
    <link href="http://cuiyungao.github.io/2016/11/15/causal/"/>
    <id>http://cuiyungao.github.io/2016/11/15/causal/</id>
    <published>2016-11-15T03:22:33.000Z</published>
    <updated>2016-11-15T06:26:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>FSE’16, University College London的work，作者William Martin, Federica Sarro and Mark Harman。</p>
<a id="more"></a>
<p>文章用CIA (Causal Impact Analysis)的方法来分析哪些因素会影响app的成功，即release如何影响app的评分和用户的评分频率。传统的correlation analysis方法（比如，Pearson方法，要求$p\leq 0.01$）只能说明两个因素之间存在关系，但并不能说明是因果关系，即<code>correlation doesn&#39;t mean causality</code>，所以作者就引用了在economic forcasting当中使用的方法——<code>causal inference</code>，应用在app release方面，提出了<code>Causal Impact Release Analysis</code> (CIRA)。</p>
<h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a><center><strong>Methods</strong></center></h3><p>文章分析了developer可以控制的因素（三个因素，<code>P</code> price， <code>L</code> descriptoin length，和 <code>RT</code> release text，即changelog）与app的success（三个标准，<code>R</code> rating, <code>N</code> number of ratings, 和<code>NW</code> number of ratings per week）之间是否存在因果关系。Causal inference通过observational data知道post-event的变化，然后决定一个事件原因的重要性，文章给出了为什么用causal impact analysis（CIA独立地对待control set和target set，用整个control set来提供global variance，因为大多数app通常不会接受相同的干预——这是differences-in-differences analysis方法的前提），以及如何使用causal impact analysis，如下图所示。</p>
<center><img src="/img/papers/causal1.png" width="70%"></center>

<p>虽然Developer update的外部因素暂时无法得到，但是CIA可以检测这种外部因素，而且作者做了现实调查的补充。</p>
<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a><center><strong>Experiment</strong></center></h3><p>实验基于从Google Play上Feb. 2015到Feb. 2016间收集的38,858个apps。这些apps均是在每一类的free/paid apps的前540当中。Control set（没有更新信息）680个，target set（去掉最前和最后的3个周）包含14,592个apps和26,339个releases。文章致力于解决5个问题 (research questions)：</p>
<h4 id="RQ1"><a href="#RQ1" class="headerlink" title="RQ1"></a>RQ1</h4><p>App的metrics随时间变化么？<mark>这个可以作为文章的motivation</mark>。作者发现N和NW有很大的标准差，但是R比较小，但是rating frequency在target set中的波动比较大。</p>
<h4 id="RQ2"><a href="#RQ2" class="headerlink" title="RQ2"></a>RQ2</h4><p>App的release数据（e.g., app的更新速度或者间隔）与app的成功（rating和number of ratings的差异）有关系么？作者通过correlation来计算，前者因素采用中值。</p>
<p>作者发现success metrics和release数据之间的correlation仅仅是weak significant correlation。</p>
<h4 id="RQ3"><a href="#RQ3" class="headerlink" title="RQ3"></a>RQ3</h4><p>App的release影响app的成功么？Correlation effect是整体的相关度，对<mark>特定</mark>的个体不是很有效, <mark>correlation is not causation</mark>，所以作者采用CIA方法来分析R, N, NW是否有显著变化。结果发现target releases当中33%显著影响一种sueccess metric，11%影响超过一种的success metric。之后作者分析Control set的大小是否有影响？（因为CIA要采用整个control set）发现control set的大小无影响。</p>
<h4 id="RQ4"><a href="#RQ4" class="headerlink" title="RQ4"></a>RQ4</h4><p>什么是impactful的releases?作者分析了在releases当中最常出现的terms （LDA参数设置成100个topics，并且解释，这样既能保证多样性，又能防止过分多样），这些top的terms出现频率是怎样的，以及candidate causes的影响是什么（用<mark>Wilcoxon test and Vargha and Delaney’s $\hat{A}_{12}$ effect size comparison</mark>来分析significant release和non-significant release之间的显著差异性）。</p>
<p>显著影响下一个版本的apps有较高的价格或者较多的文本描述，releases积极影响rating的多出现在free apps和有价格高的paid apps中，并且发现top的terms中，bug fix比new feature多。</p>
<h4 id="RQ5"><a href="#RQ5" class="headerlink" title="RQ5"></a>RQ5</h4><p>CIA对developer有用么？通过给developer发邮件的方法来获悉developer对CIA的看法，包括四个方面，是否同意检测到的显著性，变化的外部因素（比如广告），会因为我们的发现改变release的策略么，是否接受进一步的报告，以及进一步学习影响release的因素。</p>
<p>作者给4,302个developer发邮件，仅仅有138个给反馈。39/55个developer认可CIRA。<mark>学习文章作者解释数字的形式，没有采用百分比的形式</mark>。</p>
<h3 id="Others"><a href="#Others" class="headerlink" title="Others"></a><center><strong>Others</strong></center></h3><p>作者在<mark>贡献部分就主要描述了自己的发现</mark>，在方法部分，作者<mark>详细介绍了数据的选择</mark>，总结了为什么选用这些app（popular apps很有可能被下载和回复评论，可以有大量的app releases），为什么选择one week的update interval，dropout的app不影响CIA，以及为什么要自己计算rating（Google Play自己呈现的都是整数，作者用人数乘上rating然后平均来获得最终的rating）。<mark>数据的展示图值得借鉴</mark>，如下图所示。</p>
<center><img src="/img/papers/causal2.png" width="80%"></center>

<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><center><strong>Reference</strong></center></h3><p><a href="http://dl.acm.org/citation.cfm?id=2950320" target="_blank" rel="external">Causal Impact Analysis for App Releases in Google Play</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;FSE’16, University College London的work，作者William Martin, Federica Sarro and Mark Harman。&lt;/p&gt;
    
    </summary>
    
      <category term="papers" scheme="http://cuiyungao.github.io/categories/papers/"/>
    
    
      <category term="Mobile Apps" scheme="http://cuiyungao.github.io/tags/Mobile-Apps/"/>
    
      <category term="FSE" scheme="http://cuiyungao.github.io/tags/FSE/"/>
    
  </entry>
  
  <entry>
    <title>PRADA Proritizing Android Devices for Apps by Mining Large-Scale Usage Data</title>
    <link href="http://cuiyungao.github.io/2016/11/14/PRADA/"/>
    <id>http://cuiyungao.github.io/2016/11/14/PRADA/</id>
    <published>2016-11-14T14:26:52.000Z</published>
    <updated>2016-11-15T03:22:12.000Z</updated>
    
    <content type="html"><![CDATA[<p>ICSE’16,北大高性能软件技术实验室，UIUC (Tao Xie), 密歇根大学和豌豆荚实验室 (CTO和co-founder, Feng Feng) 的合作。</p>
<a id="more"></a>
<p>Android设备模型的多样性增加了app测试的负担，而依据各种手机类型在市场上的股份占有量来决定测试手机并不可靠（作者通过实验验证了这个假设），文章通过豌豆荚收集用户的app的使用记录（浏览记录，主要指利用流量的online时间）来对测试手机进行rank，对新的app则依据同一类的手机（豌豆荚自动分类方法）找到测试的手机。</p>
<p>文章的优势在于数量大（”Game”和”Media”）类的3,861,444个用户， 14,709个使用数据 (usage data), 14,000个设备类型 (device models，指的是硬件标准上的不同)。</p>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a><center><strong>Introduction</strong></center></h3><p>Introduction的写作思路值得学习，首先说明app现在应用非常广泛，developer可以app开发中获利；然后说明为什么选用Android这个平台（因为android设备类型非常多）。</p>
<p>接着说明android设备的heavily fragmented distribution这个特性增加了开发者在设计，开发，维护，质量保证和获利当中的挑战（94%的developer认为fragmentation是阻止他们使用安卓平台的主要原因）。Developer需要考虑device-specific的很多因素，比如屏幕大小，分辨率大小和其他的硬件标准，并且举例子来说明这一点（game app）。Fragmentation也影响revenue，比如facebook从2014年开始就根据手机类型来推荐不同的广告。</p>
<p>接下来作者总结了自己的两点motivation，为什么根据market share来决定测试手机不好（market share是根据买卖手机的数量而不是用户如何使用），以及每个app在device上的使用情况是不一样的。然后作者说明本文章的方法<code>PRADA</code>，基于每个用户在手机上如何使用的情况，利用<code>operational profile</code>（system如何被使用的表示形式）的概念，来对每个app（包括新的app）来推荐测试手机。</p>
<p>之后作者踪迹了实验，包括实验数据和metric，以及baseline。最后作者总结了自己的contribution。</p>
<h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a><center><strong>Methods</strong></center></h3><p><code>PRADA</code>的<code>key idea</code>是用户活动越多的device需要被排在前面，解释了数据是怎么收集的，以及其具备的特征（Chinese version of Wandoujia），强调用户是匿名的。<code>PRADA</code>的workflow如下图所示，首先是数据收集，相同app的提取（选用已有的分类效果足够好），然后是设备模型的排序。文章解释设备模型的排序是基于两个基本原理，很有意思，第一个是<code>Pareto distribution</code>，即大部分的效果来源于一小部分原因；第二个是<code>Collective intelligence</code>，借鉴众人的智慧，相同的app可能在设备模型上共享类似的分布。作者在实验部分也验证了这两个基本原理。</p>
<center><img src="/img/papers/PRADA1.png" width="80%"></center>

<h4 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h4><p>作者定义了三个metrics，<code>device model hit</code>（模型设备rank在前面的有几个被点击，没有考虑次序），<code>average precision</code>（考虑次序，与NDCG类似），以及<code>usage data coverage</code>（rank在前面的设备的使用时间与真实的使用时间之间的比值）。后面解释什么是基于time-share的排序，app在设备上的time share是通过比值来计算的，如下，其中$Time(D_j)$为在某个具体device model上的时间，$\sum Time(D_k)$是在所有device model上的总的时间。<br>$$<br>Time\; Share(D_j\rightarrow A) = \frac{Time(D_j\rightarrow A)}{\sum Time(D_k\rightarrow A)}.<br>$$</p>
<h4 id="Collaborative-Filtering"><a href="#Collaborative-Filtering" class="headerlink" title="Collaborative Filtering"></a>Collaborative Filtering</h4><p>也就是workflow当中的<code>device model prioritization</code>部分，采用的是<code>Leave-One-Out Cross Validation</code> (LOOCV)的方法，假定一个app为新的app，然后用同类型的app来rank当前的app的测试设备。<mark>作者用了代码片段来表示算法，用一个app来举例算法的流程，感觉是不是太啰嗦了…</mark></p>
<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a><center><strong>Experiment</strong></center></h3><p>实验解决两个问题，主要是针对模型的两个基本原理，第一个是大部分的浏览时间分布在多少设备模型上，第二个问题是<code>PRADA</code>能够多有效地发现新app的测试设备模型。为了验证market share太粗粒度，<code>PRADA</code>是有效的，作者用了两个baseline，一个是appBrain上的market share，另外一个是在Wandoujia上的设备分布 (local market)。<mark>作者解释了准确率低可能存在的原因</mark>，比如说一些app是提前安装在用户手机上的，影响rank的结果。</p>
<h3 id="Others"><a href="#Others" class="headerlink" title="Others"></a><center><strong>Others</strong></center></h3><p>文章的讨论部分主要针对是分类的问题，一方面说明分类的粗粒度没有影响，另外一方面说明分类的重要性。作者特地用一个章节<code>Implications</code>来说明工具的有效性，强调发现和方法比较重要，数据收集的合法性，会公开部分数据，以及会开放tool给developer使用<mark>这就弥补了developer拿不到数据的问题，很有效</mark>。在<code>Threats to validaty</code>部分，作者分析了几个方面，包括市场的局限性（中国），使用数据的单一性（仅仅是用户的浏览时间），time sensitivity（仅仅用了3个月的用户记录），device的发布时间（只能预测已经拿到数据的设备模型），以及分类的局限性。</p>
<p>总的感觉是文章解释比较详细，虽然有时候感觉啰嗦，但是解释的很清楚，细节的地方都有讲，思路清晰。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><center><strong>Reference</strong></center></h3><p><a href="http://www-personal.umich.edu/~qmei/pub/icse2016-prada.pdf" target="_blank" rel="external">PRADA: Proritizing Android Devices for Apps by Mining Large-Scale Usage Data</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ICSE’16,北大高性能软件技术实验室，UIUC (Tao Xie), 密歇根大学和豌豆荚实验室 (CTO和co-founder, Feng Feng) 的合作。&lt;/p&gt;
    
    </summary>
    
      <category term="papers" scheme="http://cuiyungao.github.io/categories/papers/"/>
    
    
      <category term="ICSE" scheme="http://cuiyungao.github.io/tags/ICSE/"/>
    
      <category term="Mobile Apps" scheme="http://cuiyungao.github.io/tags/Mobile-Apps/"/>
    
  </entry>
  
  <entry>
    <title>Release Planning of Mobile Apps Based on User Reviews</title>
    <link href="http://cuiyungao.github.io/2016/11/11/release/"/>
    <id>http://cuiyungao.github.io/2016/11/11/release/</id>
    <published>2016-11-11T07:22:53.000Z</published>
    <updated>2016-11-11T09:28:12.000Z</updated>
    
    <content type="html"><![CDATA[<p>ICSE’16的一篇<a href="http://dl.acm.org/citation.cfm?id=2884818" target="_blank" rel="external">文章</a>，意大利university of Sannio和Free University of Bozen-Bolzano。</p>
<a id="more"></a>
<p>这篇文章的亮点在于实现了完整的给developer推荐review的tool——CLAP (Crowd Listener for releAse Planning)，实验验证部分很完善，而且找到了业界的三个公司的project manager来给出好评；虽然方法比较trivial。分类比较粗，仅仅是new feature，bug report和other三种。<mark>感觉最主要的是实验验证很完整，非常有说服力，这也是在我之后的work中需要加强的。</mark></p>
<h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a><center><strong>Methods</strong></center></h3><p>CLAP总共有三步：</p>
<h4 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h4><p>将user reviews分类成new feature, bug report和other三类。<br>分类之前的 <strong>预处理</strong> 包括处理negations (就是有些词虽然在用户review中存在，但是用户是持褒义的态度)，去掉<a href="https://code.google.com/archive/p/stop-words/" target="_blank" rel="external">stop-words</a>和stemming (采用Poter stemmer)，统一近义词 (从1,000条评论中自定义近义词词表，<mark>这个可以用ISSRE’16的 work来进行补充</mark>)，和提取n-grams。<br><strong>分类特征</strong> 包括(i)评论评分，(2)从review中提取的n-grams，(3)在预处理之后剩下的词。<strong>分类方法</strong> 为Random Forest machine learnig algorithm，文章解释说选取这个方法是在比较了不同的machine learner package之后。</p>
<h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h4><p>分类相关的reviews，对每一类下面的review进行分类排序。<br><strong>分类</strong> DBSCAN来进行排序，距离为review的tf-idf之间的cosine similarity，设置<em>minPts</em>为2 (两个相关的review就可以组成一类)，$\epsilon$为两点之间的最小距离，经实验设置为0.6。<strong>排序</strong> 特征为每一类中的review的数目，每一类的平均评分，类的平均评分与app总评分之间的差距，用户新旧版本评分的平均差异，以及评论中提到device的数目。分成的大的三类中的排序标准都不太一样。这些特征用来建立Random Forest decision tree。</p>
<h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><p>实现CLAP prototype。<br>结果如图所示，呈现出用户经常提到的5个单词，developer可以与其进行交互，表示是否想fix当前问题，以此来扩充自动排序的训练集。</p>
<center><img src="/img/papers/release1.png" width="80%"></center>

<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a><center><strong>Experiment</strong></center></h3><p>实验对象为210个app的1,763条评论，对于我们的数据集来说非常少；但是实验非常完备，主要回答四个问题：</p>
<h4 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h4><p>对review的三种分类是否准确。<br>作者对1,000条review进行人工label，最终有235个bug report，179个new feature，596个其它，用10-fold cross validation来计算平均准确率。</p>
<h4 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h4><p>由CLAP生成的三个类中rank出来的term是否有用。<br>作者人工选取了5个app (Facebook, Twitter, Yahoo mobile client, Viber, 和WhatsApp) 的200条用户评论，每个app的40条评论中bug report和new feature各一半。三个有5年以上经验的app开发者对这些review进行人工归类 (<mark>当中作者的描述值得学习</mark>)。作者用<em>MoJo eFfectiveness Measure (MoJoFM)</em> 比较了人工标注的结果跟DBSCAN的结果，发现DBSCAN的$\epsilon$取0.6时结果最佳，并且分析了结果不好的原因出现在哪些类里面，为什么会有失败的例子。</p>
<h4 id="问题3"><a href="#问题3" class="headerlink" title="问题3"></a>问题3</h4><p>由CLAP推荐的new feature或者bug是否有效。<br>这个主要是跟AR-Miner进行对比，感觉这部分的比较很多描述，做的很细致，不知道怎么在自己的work中达到这种效果。DBSCAN结果的中心点为被认为是rank出来的评论，然后跟AR-Miner进行比较，metric为AUC (area under curve)，因为文章中用到的方法跟AR-Miner不一样。文章的准确率很低，但是作者说”However, we still believe that this level of accuracy represents a good starting point for helping app developers duing release planning activities.”, “we did not envision our tool to be used as a black box taking user reviews as input and producing a list of prioritized clusters. We rather look at it as a support for app developers interacting with them”。感觉解释得很屌呀…</p>
<h4 id="问题4"><a href="#问题4" class="headerlink" title="问题4"></a>问题4</h4><p>采访了3个公司的project manager，对这个tool的看法。<br>问题分为四个方面，用户评论是否有用，排序阶段的分类考虑到的因素是否全面合理，评论的分类是否有效，还有工具是否有用。对三个人的采访描述的详细到位。<mark>有几点值得关注&lt;/mark。，一个是manager比较关注competitive apps的特征是怎样的，还有大的版本跟小的版本考虑的问题的区别，还有就是最好详细的bug list，而不是简单的high/low quality，最后就是自动生成app的changelog (release note，这个已经在FSE中有<a href="https://www.ifi.uzh.ch/dam/jcr:00000000-14e5-028d-0000-0000307919c8/C23.pdf" target="_blank" rel="external">paper</a>这么做了)。</mark></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ICSE’16的一篇&lt;a href=&quot;http://dl.acm.org/citation.cfm?id=2884818&quot;&gt;文章&lt;/a&gt;，意大利university of Sannio和Free University of Bozen-Bolzano。&lt;/p&gt;
    
    </summary>
    
      <category term="papers" scheme="http://cuiyungao.github.io/categories/papers/"/>
    
    
      <category term="ICSE" scheme="http://cuiyungao.github.io/tags/ICSE/"/>
    
      <category term="User Review" scheme="http://cuiyungao.github.io/tags/User-Review/"/>
    
  </entry>
  
  <entry>
    <title>Collaborative Recurrent Autoencoder Recommend while Learning to Fill in the Blanks</title>
    <link href="http://cuiyungao.github.io/2016/11/09/collaborative/"/>
    <id>http://cuiyungao.github.io/2016/11/09/collaborative/</id>
    <published>2016-11-09T09:26:32.000Z</published>
    <updated>2016-11-09T14:21:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>NIPS’16的<a href="https://arxiv.org/abs/1611.00454" target="_blank" rel="external">论文</a>，作者HKUST Hao Wang, Xingjian Shi, <a href="https://arxiv.org/abs/1611.00454" target="_blank" rel="external">Dit-Yan Yeung</a>。</p>
<a id="more"></a>
<p>本文的主要贡献是提出collaborative recurrent autoencoder (CRAE)，将CF (collaborative filtering)跟RNN结合在一起，也就是将用户的rating信息跟content结合起来，提高推荐的准确率，并且可以用于sequence generation task。同时，提出了解决overfitting的两种方法，即wildcard denoising和beta-pooling；采用贝叶斯，可以无缝结合其它辅助信息来提高performance。</p>
<h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a><center><strong>Methods</strong></center></h3><p>传统的LSTM模型没有考虑进噪声，对不足的训练数据稳定性不好，文章提出RRN (robust recurrent networks)，为RNN的加噪版本，RRN中的噪声直接在网络中向前或者向后传播，不需要分开的网络来估计latent variables的分布，更容易实现且效率高。CARE的模型如下图所示，其中$e^{\prime (j)}_t$为$e^{(j)}_t$的加噪版本，$K$为最终表示$\gamma_j$的维度，中间层单元为$\theta_j$，$\mathbf{v}_j$和$\mathbf{u}_i$为隐含层向量，输出状态$\mathbf{h}^{(j)}_t$，gate units (比如$\mathbf{h}^{o(j)}_t$),和cell state $\mathbf{s}^{(j)}_t$的维度为$K_W$。序列处理的信息保存在cell state $\mathbf{s}_t$和输出状态$\mathbf{h}_t$中，两个RRN可以组合形成编码译码结构。</p>
<center><img src="/img/papers/collaborative1.png" width="90%"></center>

<p><code>Wildcard denoising</code>的目的是缓解overfitting，做法是随机选择一些词，替换成”<wildcard>“，而不是直接扔掉词，实验验证准确率会提成20%左右。<code>Beta-pooling</code>的目的是将向量序列pool成固定长度为$2K_W$的单向量，帮助rating matrix的矩阵分解；因为不同序列可能需要不同大小的权重，所以需要变长的beta向量来帮助pooling，文章采用beta分布。</wildcard></p>
<p>Learning的过程采用MAP，类似于CDL和DTR。学到$\mathbf{U}$和$\mathbf{V}$之后，我们可以预计评分$\mathbf{R}_{ij}=\mathbf{u}^T_i\mathbf{v}_j$。</p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a><center><strong>Experiments</strong></center></h3><p>比较的主要方法（总共有5种，选取其中两种解释）：</p>
<ol>
<li>CTR (collaborative topic reguression)<br>将topic model和probabilistic matrix factorization (PMF)，但是CTR采用bag-of-words的表示形式，忽略了词序和每个词的局部语境，而这些对文章表示和word embeddings能提供有价值的信息。</li>
<li>CDL (collaborative deep learning)<br>将CF和probabilistic stacked denoising autoencoder (SDAE)结合起来，是一个以bag-of-words为输入的feedforward模型，并不能解决sequence generation的问题。</li>
</ol>
<p>实验为在两个公用的数据集上<a href="http://www.citeulike.org/faq/data.adp" target="_blank" rel="external"><em>CiteULike</em></a>和<a href="http://www.wanghao.in/" target="_blank" rel="external"><em>Netflix</em></a>的推荐和sequence generation。在运行速度上，CRAE表现跟CDL类似。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;NIPS’16的&lt;a href=&quot;https://arxiv.org/abs/1611.00454&quot;&gt;论文&lt;/a&gt;，作者HKUST Hao Wang, Xingjian Shi, &lt;a href=&quot;https://arxiv.org/abs/1611.00454&quot;&gt;Dit-Yan Yeung&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="papers" scheme="http://cuiyungao.github.io/categories/papers/"/>
    
    
      <category term="RNN" scheme="http://cuiyungao.github.io/tags/RNN/"/>
    
      <category term="Recommendation" scheme="http://cuiyungao.github.io/tags/Recommendation/"/>
    
      <category term="NIPS" scheme="http://cuiyungao.github.io/tags/NIPS/"/>
    
  </entry>
  
  <entry>
    <title>Phrase-Based Extraction of User Opinions in Mobile App Reviews</title>
    <link href="http://cuiyungao.github.io/2016/11/01/phrasebased/"/>
    <id>http://cuiyungao.github.io/2016/11/01/phrasebased/</id>
    <published>2016-11-01T08:47:12.000Z</published>
    <updated>2016-11-03T03:45:21.000Z</updated>
    
    <content type="html"><![CDATA[<p>ASE’16上的short paper，去年ASE中过一篇<a href="https://arxiv.org/pdf/1505.04657.pdf" target="_blank" rel="external">keyword-based extraction</a>。</p>
<a id="more"></a>
<h3 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a><center><strong>Goal</strong></center></h3><p>目的是从review中获取phrase，并monitor其趋势。</p>
<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a><center><strong>Method</strong></center></h3><p>在对数据进行预处理之后，挖掘phrase templates，即找出有效的phrase对应的PoS序列，同时对phrase的frequency进行过滤，去掉次数少于20次的，长度大于8的phrase；保留功能词(e.g., “and”, “but”)，而不是将它们替换成相应的PoS标签；人工检测每个phrase的有效性。这一步之后将一条review分成几个句子，然后PoS tagger生成PoS序列，如果一个phrase满足提前定义好的phrase template，则保留这个phrase，所有的sub-sequence跟含stop words的phrase都去掉；将助动词”do”, “can”, “will”等词替换成相应的pos tag “MD”，因为它们对最终的phrase语义没有多大贡献；将代词”my”, “yours”, “our”等词也做相同的处理。最后一步为对phrase进行聚类，先用word2vec将词转换成vector，计算相似度用自己定义的如下公式，最后进行soft clustering。</p>
<p>$$<br>phraseSim(\rho_a, \rho_b)=\frac{\sum_{i=1}^k\delta_i}{n+m-k},<br>$$</p>
<p>式中，$k$为词对$\delta$的数目，$\rho_a, \rho_b$包含词的数目分别是$n$和$m$，$\delta$为一个词对的相似度(cosine similarity)。</p>
<h3 id="Comments"><a href="#Comments" class="headerlink" title="Comments"></a><center><strong>Comments</strong></center></h3><ol>
<li>本文采用的数据集为amazon.com上的120个app，于2015.1.01-9.01间收集，有大约20万条高质量的review；作者选用amazon的原因是认为它比一般的review有更少的noise。所以作者的方法在noise比较大的时候是否有效，存在质疑。</li>
<li>只用了两个case study,没有ground truth，所以用changelog作为ground truth有其局限性，但是也可以作为ground truth。</li>
<li>对于没有定义的textual expression无效，即假如有些规则没有定义的话，则不能提取相应的Phrase。</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ASE’16上的short paper，去年ASE中过一篇&lt;a href=&quot;https://arxiv.org/pdf/1505.04657.pdf&quot;&gt;keyword-based extraction&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="papers" scheme="http://cuiyungao.github.io/categories/papers/"/>
    
    
      <category term="NLP" scheme="http://cuiyungao.github.io/tags/NLP/"/>
    
      <category term="App Reviews" scheme="http://cuiyungao.github.io/tags/App-Reviews/"/>
    
      <category term="ASE&#39;16" scheme="http://cuiyungao.github.io/tags/ASE-16/"/>
    
  </entry>
  
  <entry>
    <title>StarrySky A Practical System to Track Millions of High-Precision Query Intents</title>
    <link href="http://cuiyungao.github.io/2016/09/05/starry/"/>
    <id>http://cuiyungao.github.io/2016/09/05/starry/</id>
    <published>2016-09-05T09:44:44.000Z</published>
    <updated>2016-09-05T10:13:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>WWW’16的文章。Ye, Qi, Feng Wang, and Bo Li. “Starrysky: A practical system to track millions of high-precision query intents.” Proceedings of the 25th International Conference Companion on World Wide Web. International World Wide Web Conferences Steering Committee, 2016.<br><a id="more"></a><br>这篇文章用来解决广告搜索的问题。搜索广告的现状是主要基于关键字匹配的搜索模式。存在的问题有用户query比较短、特征稀疏、歧义性强；字面上匹配<mark>缺乏意图相关特征</mark>；广告缺乏相关性数据。这就会导致返回不恰当的广告，降低用户体验。</p>
<h3 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a><center><strong>Goal</strong></center></h3><p>建立用户query与intention之间的映射关系，处理高频与长尾查询，平衡precision和coverage。(长尾关键词[long tail keyword]指的是网站上非目标关键词但也可以带来搜索流量的关键词。)</p>
<p>现有的intention recognition主要有三种方法：短文本聚类，topic modeling，查询分类（yahoo采用）。特点是可发现细粒度意图，但是难覆盖长尾查询；不同数据集topic难以对应，短文本分析精确度不够；类有几十到上千类，粒度较粗。</p>
<p>本文用到的是第三种，即<mark>查询分类</mark>。基本假设是点击相同网页的查询意图相似，所以需要对网络进行分类。由于查询的意图会有细微差别，所以需要分类的算法具有一定的抗噪性，文中采用社团发现算法(MMO, Multi-resolution Modularity Optimization)。识别结构如下图所示。在concept之间建立联系，对聚类纯度和类间的相关性进行计算。</p>
<center><img src="/img/papers/starry2.png" width="100%"></center>

<h3 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a><center><strong>Framework</strong></center></h3><p>整体框架如图所示。抽取query-url关系有1300万，有1650万url，如果两个query之间存在一个同点击，则在两个query之间连接一条边，设定阈值进行过滤，最终得到包含1300万查询节点，8亿条边的查询点击网络。在inference阶段，用贝叶斯的方法发现候选概念，同时对候选集推出的概念按照出现的概念进行rejection，文中提到了两种rejection的方式。</p>
<center><img src="/img/papers/starry1.png" width="100%"></center>

<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><center><strong>Reference</strong></center></h3><p>[1] <a href="http://dl.acm.org/citation.cfm?id=2890588" target="_blank" rel="external">StarrySky: A Practical System to Track Millions of High-Precision Query Intents</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;WWW’16的文章。Ye, Qi, Feng Wang, and Bo Li. “Starrysky: A practical system to track millions of high-precision query intents.” Proceedings of the 25th International Conference Companion on World Wide Web. International World Wide Web Conferences Steering Committee, 2016.&lt;br&gt;
    
    </summary>
    
      <category term="papers" scheme="http://cuiyungao.github.io/categories/papers/"/>
    
    
      <category term="Graph" scheme="http://cuiyungao.github.io/tags/Graph/"/>
    
      <category term="Clustering" scheme="http://cuiyungao.github.io/tags/Clustering/"/>
    
      <category term="Query Intention" scheme="http://cuiyungao.github.io/tags/Query-Intention/"/>
    
  </entry>
  
  <entry>
    <title>Topic Modeling</title>
    <link href="http://cuiyungao.github.io/2016/09/02/baidu1/"/>
    <id>http://cuiyungao.github.io/2016/09/02/baidu1/</id>
    <published>2016-09-02T09:29:02.000Z</published>
    <updated>2016-09-02T10:08:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>百度周讲总结，这次主要讲了topic model的基础知识。<br><a id="more"></a><br>首先是各种分布基础。</p>
<h3 id="二次分布vs多项分布"><a href="#二次分布vs多项分布" class="headerlink" title="二次分布vs多项分布"></a><center><strong>二次分布vs多项分布</strong></center></h3><ol>
<li>Binomial vs. Bernolli，两者表示形式相同，都为p(x), x\in{0,1}，区别在于前者是多次试验，后者为一次试验；</li>
<li>Multinomial vs. Categorical/Discrete，假定参数为$\overrightarrow{\alpha}\in simplex(k)$，则有前者$p(n_1,…,n_k)=\frac{N!}{\prod_in_i!}\alpha_i^{n_i}$，其中$i\in[1,k]$，$\sum_in_i=N, \sum_i\alpha_i=1$；后者有$p(x=i)=\alpha_i$,$p(n_1,..,n_k)=\prod_i\alpha_i^{n_i}$。</li>
</ol>
<p>最大似然multinomial之后，我们有:<br>$$<br>{max}_{\alpha_i}\sum_in_i log\alpha_i + \lambda(1-\sum_i\alpha_i)，<br>$$<br>解得$\alpha_i=\frac{n_i}{\sum_i n_i}$。</p>
<p>通常我们会在分子跟分母上加上先验，服从$\alpha\sim Dir([\beta,\beta,…,\beta])$，主要目的是smooth，即$\alpha_i=\frac{n_i+\beta}{\sum_i n_i+\beta}$。</p>
<h3 id="Gamma-Distribution"><a href="#Gamma-Distribution" class="headerlink" title="Gamma Distribution"></a><center><strong>Gamma Distribution</strong></center></h3>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;百度周讲总结，这次主要讲了topic model的基础知识。&lt;br&gt;
    
    </summary>
    
      <category term="daily" scheme="http://cuiyungao.github.io/categories/daily/"/>
    
    
      <category term="NLP" scheme="http://cuiyungao.github.io/tags/NLP/"/>
    
      <category term="Baidu" scheme="http://cuiyungao.github.io/tags/Baidu/"/>
    
      <category term="Topic Model" scheme="http://cuiyungao.github.io/tags/Topic-Model/"/>
    
  </entry>
  
  <entry>
    <title>Leveraging Sentence-Level Information with Encoder LSTM for Semantic Slot Filling</title>
    <link href="http://cuiyungao.github.io/2016/09/02/leveraging/"/>
    <id>http://cuiyungao.github.io/2016/09/02/leveraging/</id>
    <published>2016-09-02T05:44:53.000Z</published>
    <updated>2016-09-02T07:03:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>这是在Arxiv 23, Aug, 2016的文章，作者Gakuto Kurata (IBM research),和Bing Xiang, Bowen Zhou, Mo Yu (IBM Watson)。<br><a id="more"></a><br>文章将slot filling结合sentence-level的信息，提出了<code>encoder-labeler LSTM</code>，即分为encoder和labeler两部分。<code>Encoder</code>基于LSTM将输入的句子编码成固定长度的向量，这个向量被用来作为<code>labeler</code> hidden layer的初始状态。这样，就可以预测label sequence了。</p>
<h3 id="LSTM-for-Slot-Filling"><a href="#LSTM-for-Slot-Filling" class="headerlink" title="LSTM for Slot Filling"></a><center><strong>LSTM for Slot Filling</strong></center></h3><p>用于slot filling的传统LSTM方法，即<code>labeler LSTM(W)</code>，将每个word$x_t$表示成$V$维的one-hot向量，这个向量转换成embedding的形式$Ex_t$，其中$E\in \mathbb{R}^{d_e\times V}$为word embedding matrix。<code>Context Window</code>用来取$k$个前面和后面的词$Ex_{t-k}^{t+k}\in \mathbb{R}^{d_e(2k+1)}$作为LSTM的输入，而不是单单输入一个词。紧接着softmax预测输出label，BPTT用来更新迭代parameters。如下图(a)。</p>
<p>这是比较传统的方法，<mark>它不能考虑label之间的依赖关系</mark>。为了弥补这个问题，文章提出了<code>labeler LSTM(W+L)</code>,即前一个time step输出的label作为当前time step的hidden state，并与当前词相结合。在training的过程中，<mark>label用one-hot-vector的形式表示</mark>，用<code>left-to-right beam search</code>做evaluation。如下图(b)。</p>
<p><code>Encoder-labeler LSTM(W)</code>和<code>encoder-labeler LSTM(W+L)</code>如图(d)和(e)所示。训练部分跟传统的<code>labeler LSTM</code>类似，但是labeler LSTM当中的error通过BPTT的方法更新encoder LSTM。跟以往的方法不同，输入序列被使用了两次，但是embedding matrix都是相同的。</p>
<p>其它考虑sentence-level信息的方法还有bi-directional LSTM以及attention-based methods。前者只是在一个特定的词的周围建模，没有考虑整个句子的信息，文章中的方法用<code>encoder-labeler LSTM</code>来编码整个句子的信息，并基于编码的信息来预测槽位；而后者更适用于输入跟输出长度不对等的情况，而且对于slot filling，输入的词跟输出的词有着很强的关联性，文章用<code>context window</code>的方法来对应attention。</p>
<center><img src="/img/papers/leveraging1.png" width="100%"></center>

<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a><center><strong>Experiment</strong></center></h3><p>实验分为两部分，一部分是基于已有的数据集ATIS corpus (training data是4,978个句子，evaluation是893个句子)，第二部分是融合了MIT restaurant corpus和MIT movie corpus。Evaluation采用F1-score，用<code>ADAM</code>来控制learning rate，设置<code>dropout</code>为0.5。实验中<mark>句子的结尾没有加终止符</mark>，因为输入跟输出的sequence长度是一样的。结果如下表所示，encoder-labeler LSTM(W+L)的效果不如encoder-labeler LSTM(W)的原因是中间的label预测错误导致。</p>
<center><img src="/img/papers/leveraging2.png" width="60%"></center>

<p>与其它方法的如下图，更说明了方法的有效性。</p>
<center><img src="/img/papers/leveraging3.png" width="60%"></center>

<p><mark>结合slot filling的training过程跟intent分类的结果可能会更完善已有的方法。</mark></p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><center><strong>Reference</strong></center></h3><p>[1] <a href="https://arxiv.org/pdf/1601.01530v4.pdf" target="_blank" rel="external">Leveraging Sentence-Level Information with Encoder LSTM for Semantic Slot Filling</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是在Arxiv 23, Aug, 2016的文章，作者Gakuto Kurata (IBM research),和Bing Xiang, Bowen Zhou, Mo Yu (IBM Watson)。&lt;br&gt;
    
    </summary>
    
      <category term="papers" scheme="http://cuiyungao.github.io/categories/papers/"/>
    
    
      <category term="LSTM" scheme="http://cuiyungao.github.io/tags/LSTM/"/>
    
      <category term="Slot Filling" scheme="http://cuiyungao.github.io/tags/Slot-Filling/"/>
    
      <category term="Seq2Seq" scheme="http://cuiyungao.github.io/tags/Seq2Seq/"/>
    
  </entry>
  
  <entry>
    <title>Machine Comprehension Using Match-LSTM and Answer Pointer</title>
    <link href="http://cuiyungao.github.io/2016/09/01/machine/"/>
    <id>http://cuiyungao.github.io/2016/09/01/machine/</id>
    <published>2016-09-01T09:48:16.000Z</published>
    <updated>2016-09-02T01:49:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>这是发在Arxiv 29, Aug, 2016的文章，作者Shuohang Wang和Jing Jiang (SMU).<br><a id="more"></a><br>文章的目的是机器理解(machine comprehension)，利用最新发布的数据集Stanford Question Answering Dataset (SQuAD，提供了大量的真实问题和人工创建的答案)。这个数据集的挑战有两个方面，首先答案不是取自于一个小的候选集，而是<mark>从原文来进行抽取</mark>；其次是答案的<mark>长度不同</mark>。本文基于两个LSTM的模型，<code>match-LSTM</code>和<code>Pointer Net</code>，前者为了提取上下文需要(textual entailment)，后者为了限制输出的tokens来自输入序列。</p>
<p>这个新的数据集的特殊之处在于<mark>许多问题是原文的解释</mark>。文章利用了这个特殊之处来进行机器理解。文章贡献在于提出了<code>new end-to-end neural network models for machine comprehension</code>。文章的一些模型跟思路可以用在以后的research中，所以这里做简单记录。</p>
<h3 id="Match-LSTM"><a href="#Match-LSTM" class="headerlink" title="Match-LSTM"></a><center><strong>Match-LSTM</strong></center></h3><p>Match-LSTM的主要作用是预测上下文需求，即给定两个句子，其中一句是前提(premise)，一句是假设(hypothesis)，预测前提是否是假设的必要。Match-LSTM有序列性地经过hypothesis的tokens。在hypothesis的每个位置，<code>attention mechanism</code>用来获取premise的weighted vector representation。本质上，match-LSTM将attention-weighted premise加到每一个hypothesis的token上，并用这个matching的结果预测。</p>
<h3 id="Pointer-Net"><a href="#Pointer-Net" class="headerlink" title="Pointer Net"></a><center><strong>Pointer Net</strong></center></h3><p>Pointer net主要适用于一类问题，即输出序列的token必须要来自于输入序列的token。</p>
<h3 id="Proposed-Model"><a href="#Proposed-Model" class="headerlink" title="Proposed Model"></a><center><strong>Proposed Model</strong></center></h3><p>文章提供了两种模型,<code>sequence model</code>和<code>boundary model</code>，如下图。两个模型都有三层网络，即<code>preprocessing layer</code>，<code>match-LSTM layer</code>和<code>answer pointer layer</code>；区别在于输出，前者输出整个答案的tokens，后者输出答案开始和结束的token，取中间的tokens作为答案。<mark>Boundary model巧妙地保证了输出的连贯性。</mark></p>
<center><img src="/img/papers/machine1.png" width="100%"></center>

<h4 id="LSTM-Preprocessing-Layer"><a href="#LSTM-Preprocessing-Layer" class="headerlink" title="LSTM Preprocessing Layer"></a><strong>LSTM Preprocessing Layer</strong></h4><p>这层的作用是将token的representation结合上下文信息，LSTM的hidden layer即为passage和question的表示形式。<br>$$<br>\mathbf{H}^p = \overrightarrow{LSTM}(\mathbf{P}), \mathbf{H}^q = \overrightarrow{LSTM}(\mathbf{Q}),<br>$$<br>其中，$\mathbf{H}^p\in \mathbb{R}^{l\times P}$, $\mathbf{H}^q\in \mathbb{R}^{l\times Q}$即表示形式，$\mathbf{h}_i^p$和$\mathbf{h}_i^q$分别表示passage和question中的第$i$个token。</p>
<h4 id="Match-LSTM-Layer"><a href="#Match-LSTM-Layer" class="headerlink" title="Match-LSTM Layer"></a><strong>Match-LSTM Layer</strong></h4><p>这层的作用是引入attention，基于<code>word-by-word attention mechanism</code>得到attention weight vector $\overrightarrow{\alpha}_i\in \mathbb{R}^Q$，<br>$$<br>\overrightarrow{\mathbf{G}}_i = tanh(\mathbf{W}^q\mathbf{h}_i^q+(\mathbf{W}^p\mathbf{h}_i^p+\mathbf{W}^r\overrightarrow{\mathbf{h}}_{i-1}^r+\mathbf{b}^p)\otimes\mathbf{e}_Q), \\<br>\overrightarrow{\alpha}_i = softmax(\mathbf{w}^T\overrightarrow{\mathbf{G}}_i + \mathbf{b}\otimes\mathbf{e}_Q),<br>$$<br>得到的$\overrightarrow{\alpha}_{i,j}$表示passage中第$i$个token和question中第$j$个token中间的匹配程度。Question的weighted version的表示形式为：<br>$$<br>\overrightarrow{\mathbf{z}}_i = \begin{bmatrix}<br>\mathbf{h}_i^p \\<br>\mathbf{H}^q\overrightarrow{\alpha}_i^T<br>\end{bmatrix}.<br>$$<br>得到的向量$\overrightarrow{\mathbf{z}}_i$输入到经典的LSTM模型中即为<code>match-LSTM</code>：<br>$$<br>\overrightarrow{\mathbf{h}}_i^r = \overrightarrow{LSTM}(\overrightarrow{\mathbf{z}}_i, \overrightarrow{\mathbf{h}}_{i-1}^r).<br>$$</p>
<h4 id="Answer-Pointer-Layer"><a href="#Answer-Pointer-Layer" class="headerlink" title="Answer Pointer Layer"></a><strong>Answer Pointer Layer</strong></h4><p>用得到的$\overrightarrow{\mathbf{H}}^r$作为输入，预测输出序列。前面提到的两种模型的不同就体现在这一步，<code>sequence model</code>是生成answer sequence直到句尾，即$p(\mathbf{a}|\mathbf{H}^r)=\prod_k p(a_k|a_1, a_2, …, a_{k-1}, \mathbf{H}^r)$；而<code>boundary model</code>仅仅是找到answer的开头跟结尾，即$p(\mathbf{a}|\mathbf{H}^r)=p(a_s|\mathbf{H}^r)p(a_e|a_s, \mathbf{H}^r)$。</p>
<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a><center>Experiment</center></h3><p>结果如下表所示。hidden layer维度定义为150，发现boundary model结果最好。作者还对各种类型的问题和答案的长度进行了比较分析，发现问题答案越长的结果比较差，”when”类型的问题结果较好。<mark>文章还对现有的数据集进行了总结。</mark></p>
<center><img src="/img/papers/machine2.png" width="100%"></center>

<h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><center><strong>Reference</strong></center></h4><p>[1] <a href="http://128.84.21.199/pdf/1608.07905v1.pdf" target="_blank" rel="external">Machine Comprehension Using Match-LSTM and Answer Pointer</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是发在Arxiv 29, Aug, 2016的文章，作者Shuohang Wang和Jing Jiang (SMU).&lt;br&gt;
    
    </summary>
    
      <category term="papers" scheme="http://cuiyungao.github.io/categories/papers/"/>
    
    
      <category term="LSTM" scheme="http://cuiyungao.github.io/tags/LSTM/"/>
    
      <category term="Machine Comprehension" scheme="http://cuiyungao.github.io/tags/Machine-Comprehension/"/>
    
  </entry>
  
  <entry>
    <title>Understanding RNN</title>
    <link href="http://cuiyungao.github.io/2016/08/25/rnn/"/>
    <id>http://cuiyungao.github.io/2016/08/25/rnn/</id>
    <published>2016-08-25T02:49:14.000Z</published>
    <updated>2016-08-26T07:00:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章主要总结RNN，主要<a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" target="_blank" rel="external">出处</a>。</p>
<a id="more"></a>
<p>RNN在NLP的应用主要是两方面，一方面是可以判断两个句子的相似度；另外一方面则是可以生成新的文本。RNN的主要想法是<mark>使用sequential information</mark>。在传统的神经网络中，输入被认为是相互独立的，而RNN可以学习历史的信息，对sequence中的每一个element都进行相同的任务。另外一个想法是<mark>RNN有历史计算的<code>memory</code></mark>。这个<code>memory</code>就是网络的hidden state，所以<mark>hidden state是RNN的关键</mark>。较大的hidden layer size可以学到更复杂的patterns，但是会增加计算力。需要注意一下几点：</p>
<ol>
<li>Hidden state就是网络的memory，它获取历史信息，但是不能获取很长步骤之前的信息；</li>
<li>RNN在所有步骤之间共享参数，而传统的神经网络是每一层学习不同的参数。这能大大地减少需要学习的参数；</li>
<li>每一步不一定要有输出，这是由任务决定的；同理，每一步也不一定要有输入。</li>
</ol>
<p>因为参数在所有步骤之间共享，每一步的gradient不仅仅依赖于当前步的计算，还有之前很多步的计算，即<code>Backpropagation Through Time</code> (BPTT)。理论上，RNN绝对能处理<code>long-term dependencies</code>的情况，但是在实际应用中，RNN并不能有效地学习历史信息 (因为存在vanishing/exploding gradient problems)。LSTM是用来解决这种问题。所有的recurrent neural networks都有神经网络的重复module链的形式。在传统的RNN当中，重复的module有着非常简单的结构，比如单个的tanh层。LSTM结构也呈链状，但是在每一个单独的网络中，它有四层，而不是简单的一层。如图所示。LSTM的关键是cell state，即在图表中的上层，LSTM能够移除或者增加cell state。门(gate)的作用是选择性地让信息通过。有很多完善LSTM的方法，比如增加<code>peephole connections</code>，使用coupled forget gate和input gate来决定要forget和add的信息，以及GRU (Gated Recurrent Unit,将cell state和hidden state结合到<code>update gate</code>中)。具体的过程可以参见[1]。</p>
<center><img src="/img/daily/rnn1.png" width="100%"></center>

<p>RNN的延伸还有BRNN (Bidirectional RNN)和Deep (Bidriectioanl) RNN。前者的主要想法是时间$t$的输出不仅依赖于当前element，还有future element有关系；它的输出建立在双向的hidden state的基础之上。后者是每一个time step有很多层，这种情况通常有更高的学习能力，但通常也需要大量的训练数据。详细解释可以参考[2]。对于backpropagation，可以参考[3,4]。</p>
<p>Vanilla Neural Network的主要限制是API受限，只接受固定大小的输入和固定大小的输出，以及固定数量的计算步骤。引用原文[5]的话，<mark>If training vanilla neural nets is optimization over functions, training recurrent nets is optimization over programs.</mark></p>
<p>总结了RNN的衍生算法，比如DRAW, GAN, Pixel RNN等，可以看[6]。详细的GRU与LSTM之间的区别，可以见[8]。</p>
<p>关于初始化过程，RNN当中一般不能单纯地初始化为0，这样会导致对称计算。我们必须<mark>随机地初始化</mark>，适当地初始化会对训练结果又影响。最好的初始化依赖于<code>activation function</code>，并且<code>recommend</code>的方法是将权重随机地初始化在$[-\frac{1}{\sqrt{n}}, \frac{1}{\sqrt{n}}]$这个范围内，其中$n$是前面层的输入链接数。为了降低计算的复杂度，可以用<code>hierarchical softmax</code>或者增加<code>projection layers</code>来避免大的矩阵相乘。</p>
<p>关于<mark>vanishing/exploding gradients</mark>，主要考虑到求导部分，比如$\frac{\partial E_3}{\partial W} = \sum_{k=0}^3\frac{\partial E_3}{\partial y_3}\frac{\partial \hat{y}_3}{\partial s_3}(\prod_{j=k+1}^3\frac{\partial s_j}{\partial s_{j-1})\frac{\partial s_k}{\partial W}$。可以看到向量对向量进行求导，结果是一个矩阵，即<code>Jacobian matrix</code>。当中间连乘的值趋近于0或者较大的时候，就会出现<code>vanishing gradients</code>或者<code>exploding gradients</code>的情况。对于exploding的情况，可以简单地通过定义一个threshold来解决，而且比较容易发现，当gradients为NaN时，程序会崩溃，所以vanishing的情况更值得关注。有很多解决vanishing的方法，比如将activation function换成<code>ReLU</code>，而不是<code>tanh/sigmoid</code>，更常用的解决方法是用LSTM或者GRU (LSTM的简化版本)，这两种方法都是用来解决vanishing gradients和long-range dependencies的学习问题。具体分析可见[7]。关于parameter update，可以参见[9]，后面关于使用这些gradients的summary非常有用。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><center><strong>Reference</strong></center></h3><p>[1] <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">Understanding LSTM Networks</a><br>[2] <a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" target="_blank" rel="external">Recurrent Neural Networks Tutorial</a><br>[3] <a href="http://colah.github.io/posts/2015-08-Backprop/" target="_blank" rel="external">Calculus on Computational Graphs: Backpropagation</a><br>[4] <a href="http://cs231n.github.io/optimization-2/" target="_blank" rel="external">CS231n Convolutional Neural Networks for Visual Recognition</a><br>[5] <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="external">The Unreasonable Effectiveness of Recurrent Neural Networks</a><br>[6] <a href="https://github.com/tensorflow/magenta/tree/master/magenta/reviews" target="_blank" rel="external">Reviews of research papers</a><br>[7] <a href="http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/" target="_blank" rel="external">Backpropagation through time and vanishing gradients</a><br>[8] <a href="http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/" target="_blank" rel="external">Implementing a GRU/LSTM RNN with python and theano</a><br>[9] <a href="http://cs231n.github.io/neural-networks-3/#update" target="_blank" rel="external">Parameter updates</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章主要总结RNN，主要&lt;a href=&quot;http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/&quot;&gt;出处&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="daily" scheme="http://cuiyungao.github.io/categories/daily/"/>
    
    
      <category term="RNN" scheme="http://cuiyungao.github.io/tags/RNN/"/>
    
      <category term="Deep Learning" scheme="http://cuiyungao.github.io/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>MF, FM, 与NMF</title>
    <link href="http://cuiyungao.github.io/2016/08/24/fm/"/>
    <id>http://cuiyungao.github.io/2016/08/24/fm/</id>
    <published>2016-08-24T08:53:46.000Z</published>
    <updated>2016-08-24T13:59:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>百度周讲，这次主要讲的是MF, FM, NMF。</p>
<a id="more"></a>
<p>假设存在一个集合$S={x_i, y_i}_N$，我们的目标是由$x_0$推测出$y_0$，即$x_0-&gt;y_0$。如果$y_0=\sum_i f(x_0, x_i, S)y_i$，即权重参数是由样本集本身决定的，那么我们称其为<code>non-parametric</code>的模型，比如KNN, one-shot都是<code>non-parametric</code>的模型。</p>
<p>在线性空间中看到$x_i^Tx_j$，我们可以通过<code>kernel</code>将其转换到非线性空间。</p>
<p>在解决问题的时候，我们需要考虑三个方面，即<code>模型</code>，<code>目标</code>，跟<code>算法</code>。</p>
<h3 id="MF"><a href="#MF" class="headerlink" title="MF"></a><center><strong>MF</strong></center></h3><p>MF (matrix factorization)，即矩阵分解。假设$X\in R^{m\times n}, U\in R^{d\times m}, V\in R^{d\times n}$，则有：</p>
<ul>
<li>模型： $U, V$</li>
<li>目标： ${min}_{U,V} ||X-U^TV||_F^2 + \lambda(||U||_F^2 + ||V||_F^2)$，后面为<code>正则项</code>，<mark>一定要有，不能扔掉！</mark></li>
<li>算法： 解决这个问题的算法有很多，比如GD, SDG等。</li>
</ul>
<p>对于目标函数，在$X$中会存在missing value，这时候我们将目标函数修改为：<br>$$<br>{min}_{U,V} \sum_{i,j \\ x_{ij}可见} ||x_{ij}-u_i^Tv_j||_2^2 + \lambda(||u_i||_2^2 + ||v_j||_2^2).<br>$$</p>
<p>我们从<mark>概率的角度</mark>来理解MF，有<code>Probabilistic MF</code> (PMF)或者叫<code>Bayes MF</code>,则有：<br>$$<br>p(u)=\prod_i p(u_i), p(u_i) = G(u_i|0, I_d) \\<br>p(v)=\prod_i p(v_i), p(v_i) = G(v_i|0, I_d) \\<br>p(x_{ij}|u,v) = G(x_{ij}|u_i^Tv_j, \xi^2),<br>$$<br>我们的目标函数是$max \prod_{ij \\ x_{ij}可见} p(x_{ij})$。这种不可积的情况，可用Bayes或者sampling的方法来解决。</p>
<h3 id="FM"><a href="#FM" class="headerlink" title="FM"></a><center><strong>FM</strong></center></h3><p>FM (Factorization Machine)，应用在很多领域，比如推荐系统等等。以二阶为例，<br>$$<br>\begin{align}<br>&amp; \sum_i\sum_{j&gt;i} v_i^Tv_jx_ix_j + \sum_i w_ix_i + b \\<br>= &amp; \frac{1}{2}\sum_i\sum_j v_i^Tv_jx_ix_j - \frac{1}{2}\sum_iv_i^Tv_ix_i^2+ \sum_i w_ix_i + b \\<br>= &amp; \frac{1}{2}(\sum_i v_ix_i)^T(\sum_i v_ix_i)- \frac{1}{2}\sum_iv_i^Tv_ix_i^2 + \sum_i w_ix_i+ b.<br>\end{align}<br>$$</p>
<h3 id="NMF"><a href="#NMF" class="headerlink" title="NMF"></a><center><strong>NMF</strong></center></h3><p>NMF (Non-negative matrix factorization)，目标函数为：<br>$$<br>L = {min}_{u\geq 0 \\ v\geq 0} ||X-U^TV||_F^2.<br>$$<br>解法有很多：</p>
<ol>
<li>正常解，后面truncate；</li>
<li>log barrier  增加$-\sum_{ij}log u_{ij}$等regularizers；</li>
<li>$U = \tilde{U}\odot\tilde{U}$，解$\tilde{U}$；</li>
<li>multiplicative rule.<br>$$<br>\frac{\partial L}{\partial U} = -V(X-U^TU)^T = VV^TU - VX<br>$$<br>我们得到$U = U-\eta(VV^TU-VX)$，由于$\eta$后面的两项均为正，则可以写成$U=U\odot\frac{VX}{VV^TU}$(哪一个是分子、哪一个是分母，通过考虑增减性来判断)。<mark>这样我们就把相减的形式转换成了相乘的形式。</mark></li>
</ol>
<p><mark>物理解释：</mark>考虑隐含变量，比如PLSI跟LSI等都会用到这些概念。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;百度周讲，这次主要讲的是MF, FM, NMF。&lt;/p&gt;
    
    </summary>
    
      <category term="daily" scheme="http://cuiyungao.github.io/categories/daily/"/>
    
    
      <category term="Machine Learning" scheme="http://cuiyungao.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Pixel Recurrent Neural Networks</title>
    <link href="http://cuiyungao.github.io/2016/08/22/pixelcnn/"/>
    <id>http://cuiyungao.github.io/2016/08/22/pixelcnn/</id>
    <published>2016-08-22T09:48:44.000Z</published>
    <updated>2016-08-22T09:53:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>ICML’16 best paper. Google DeepMind的作品。 van den Oord A, Kalchbrenner N, Kavukcuoglu K. Pixel Recurrent Neural Networks[J]. arXiv preprint arXiv:1601.06759, 2016.</p>
<a id="more"></a>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ICML’16 best paper. Google DeepMind的作品。 van den Oord A, Kalchbrenner N, Kavukcuoglu K. Pixel Recurrent Neural Networks[J]. arXiv preprint arXiv:1601.06759, 2016.&lt;/p&gt;
    
    </summary>
    
      <category term="papers" scheme="http://cuiyungao.github.io/categories/papers/"/>
    
    
      <category term="RNN" scheme="http://cuiyungao.github.io/tags/RNN/"/>
    
      <category term="CNN" scheme="http://cuiyungao.github.io/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>Why Should I Trust You? Explaining the Predictions of Any Classifier</title>
    <link href="http://cuiyungao.github.io/2016/08/22/classifier/"/>
    <id>http://cuiyungao.github.io/2016/08/22/classifier/</id>
    <published>2016-08-22T03:41:00.000Z</published>
    <updated>2016-08-22T06:37:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>KDD’16。Ribeiro M T, Singh S, Guestrin C. “ Why Should I Trust You?”: Explaining the Predictions of Any Classifier[J]. arXiv preprint arXiv:1602.04938, 2016.</p>
<a id="more"></a>
<p>文章的主要贡献在于如何评判一个classifier的可靠性，提出了LIME算法。解决的问题是尽管有的分类器的准确率较高，但是分类基于的原因并不可信，所以这种分类器不应该被相信。文章的主要目的是，帮助人来决定是否要相信一个预测，在models之间选择，并改善不可信的分类器，识别其为什么不可信。</p>
<center><img src="/img/papers/classifier1.png" width="100%"></center>

<p><mark>据证明，为电影推荐或者其它一些自动化系统提供解释能够提高接受率。这个能够用在review analysis上面？</mark>Model和估计错误的原因通常有以下几种：</p>
<ol>
<li>Data leakage.无意的信号泄露到训练集和validation集中，但是真正使用的时候并不会使用这个信号。<mark>不太懂这个….</mark></li>
<li>Dataset shift.训练集跟测试集不同。</li>
<li>计算跟优化的标准不同。</li>
</ol>
<p>这种数据可靠性的explainers应该有哪些标准呢？一是<code>可解释性</code>，需要考虑到用户限制，有时候这些features并不一定被model所用，所以说explaination中的输入变量跟features可以不同；二是<code>local fidelity</code>，对一个实例的近邻的预测需要有意义。文章提出了<code>LIME</code> (Local Interpretable Model-agnostic Explanations)来对模型的可靠性进行解释。</p>
<h3 id="LIME"><a href="#LIME" class="headerlink" title="LIME"></a><center><strong>LIME</strong></center></h3><p>假设模型$g\in G$，$G$是一类potentially interpretable的模型，比如线性模型和决策树等。$\Omega(g)$为复杂度的衡量，$f(x)$表示$x$属于某个类的概率，$\pi_x(z)$定义$x$的近邻，$\mathcal{L}(f,g,\pi_x)$为在$\pi_x(z)$范围用$g$预测$f$的不可靠程度，由LIME生成的解释为：<br>$$<br>\xi(x) = {argmin}_{g\in G} \mathcal{L}(f,g,\pi_x) + \Omega(g)。<br>$$<br>算法过程如下：</p>
<center><img src="/img/papers/classifier2.png" width="70%"></center>

<h3 id="SP-LIME"><a href="#SP-LIME" class="headerlink" title="SP-LIME"></a><center><strong>SP-LIME</strong></center></h3><p>上面的LIME仅仅是针对单个实例，我们应该从整体上来评估一个模型，所以加进去了<code>pick step</code>来选择$B$个实例。如下图所示，特征$f_2$的得分较高。但是我们选择第2个和第5个文档来进行explaination预测。</p>
<center><img src="/img/papers/classifier3.png" width="70%"></center>

<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><center><strong>Reference</strong></center></h3><p>[1] <a href="https://arxiv.org/pdf/1602.04938v3.pdf" target="_blank" rel="external">“Why Should I Trust You?” Explaining the Predictions of Any Classifier</a><br>[2] <a href="https://github.com/marcotcr/lime-experiments" target="_blank" rel="external">Code</a>.可以重复试验（含数据）。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;KDD’16。Ribeiro M T, Singh S, Guestrin C. “ Why Should I Trust You?”: Explaining the Predictions of Any Classifier[J]. arXiv preprint arXiv:1602.04938, 2016.&lt;/p&gt;
    
    </summary>
    
      <category term="papers" scheme="http://cuiyungao.github.io/categories/papers/"/>
    
    
      <category term="Machine Learning" scheme="http://cuiyungao.github.io/tags/Machine-Learning/"/>
    
      <category term="Classification" scheme="http://cuiyungao.github.io/tags/Classification/"/>
    
  </entry>
  
  <entry>
    <title>A Derivation of Backpropagation in Matrix Form</title>
    <link href="http://cuiyungao.github.io/2016/08/21/backpro/"/>
    <id>http://cuiyungao.github.io/2016/08/21/backpro/</id>
    <published>2016-08-21T09:53:32.000Z</published>
    <updated>2016-08-21T10:06:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>本篇罗列了back propagation的general functions。</p>
<a id="more"></a>
<p>在神经网络中，更新权重经常用<code>batch gradient descent</code>或者<code>stochastic gradient descent</code>。后者是对单个的数据点更新权重，即$E=\frac{1}{2}||z-t||_2^2$；前者是批量地处理数据，即$E=\frac{1}{2}\sum_{i\in Batch}||z_i-t_i||_2^2$，其中，$t$是ground truth。这里就举例stochastic的方法，batch的方法类似。</p>
<p>为了减少误差函数，我们应该按照loss function梯度的逆方向来改变权重，即$w=w-\alpha_w\frac{\partial E}{\partial w}$，其中，$\alpha_w$是learning rate。假设神经网络有$L$层，$x_0$是输入向量，$x_L$为输出向量，$t$为truth vector，weight matrices为$W_1, W_2, .., W_L$，activation functions为$f_1, f_2, …, f_L$。</p>
<p>Forward Pass:<br>$$<br>x_i = f_i(W_ix_{i-1}) \\<br>E= ||x_L - t||_2^2<br>$$</p>
<p>Backward Pass:<br>$$<br>\delta_L = (x_L-t)\circ f_L^{\prime}(W_Lx_{L-1}) \\<br>\delta_i = W_{t+1}^T\delta_{i+1}\circ f_i^{\prime}(W_ix_{i-1})<br>$$</p>
<p>Weight Update:<br>$$<br>\frac{\partial E}{\partial W_i} = \delta_ix_{i-1}^T \\<br>W_i = W_i - \alpha W_i \circ\frac{\partial E}{\partial W_i}<br>$$</p>
<p>用矩阵表示变量，可以方便代码实现，并利用GPU来加速。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><center><strong>Reference</strong></center></h3><p>[1] <a href="https://sudeepraja.github.io/Neural/" target="_blank" rel="external">A Derivation of Backpropagation in Matrix Form</a>。原文有更详细的过程。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇罗列了back propagation的general functions。&lt;/p&gt;
    
    </summary>
    
      <category term="daily" scheme="http://cuiyungao.github.io/categories/daily/"/>
    
    
      <category term="Deep Learning" scheme="http://cuiyungao.github.io/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Softmax Approximations for Learning Word Embeddings and Language Modeling</title>
    <link href="http://cuiyungao.github.io/2016/08/19/softmax/"/>
    <id>http://cuiyungao.github.io/2016/08/19/softmax/</id>
    <published>2016-08-19T14:39:25.000Z</published>
    <updated>2016-08-21T09:20:12.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要介绍了softmax在word embedding方面的应用，资料来源于<a href="http://www.slideshare.net/SebastianRuder/softmax-approximations-for-learning-word-embeddings-and-language-modeling-sebastian-ruder" target="_blank" rel="external">这里</a>。</p>
<a id="more"></a>
<h3 id="Language-Modeling-Objective"><a href="#Language-Modeling-Objective" class="headerlink" title="Language Modeling Objective"></a><center><strong>Language Modeling Objective</strong></center></h3><p>语言模型的目标是最大化给定词$w_t$的前$n$个单词预测当前词的概率，即$p(w_t|w_{t-1},…,w_{t-n+1})$。对于n-gram models，即:<br>$$<br>p(w_t|w_{t-1},…,w_{t-n+1})=\frac{count(w_{t-n+1},…,w_{t-1},w_t)}{count(w_{t-n+1},..,w_{t-1})},<br>$$<br>对于神经网络，即：<br>$$<br>p(w_t|w_{t-1},…,w_{t-n+1})=\frac{exp(h^Tv_w)}{\sum_{w_i\in V}exp(h^Tv_{w_i})}.<br>$$</p>
<p>Maximum entropy models最小化同一个概率分布，即$P_h(y|x)=\frac{exp(h\cdot f(x,y))}{\sum_{y^{\prime}\in y}exp(h\cdot f(x,y^{\prime}))}$,其中$h$是一个<code>weight vector</code>，$f(x,y)$是一个feature vector。在神经网络中经常用于：</p>
<ul>
<li>Multi-class分类；</li>
<li>“Soft” selection, 比如attention, memory retrievals等。</li>
</ul>
<p>分母经常被叫做<code>partition function</code>,即$Z=\sum_{w_i\in V}exp(h^Tv_{w_i})$。<code>Softmax-based approaches</code>保持了softmax层的完整性，使得算法更高效；而<code>sampling-based approaches</code>优化估计softmax的不同的loss函数。</p>
<h3 id="Softmax-based-Approaches"><a href="#Softmax-based-Approaches" class="headerlink" title="Softmax-based Approaches"></a><center><strong>Softmax-based Approaches</strong></center></h3><p><code>Hierarchical softmax</code>可以被看做是一个二叉树，最多估计$log_2|V|$个节点，而不是所有的$|V|$个节点，如图Fig.1所示。结构比较重要，可以快速地遍历点，经常使用的结构是<code>Huffman tree</code>，对于frequent words路径短，如图Fig.2所示。</p>
<center><img src="/img/daily/softmax1.png" width="80%"></center><br><center>Fig.1 Hierarchical Softmax</center><br><center><img src="/img/daily/softmax2.png" width="80%"></center><br><center>Fig.2 Hierarchical Softmax [Mnih and Hinton, 2008]</center>

<p><code>Differentiated Softmax</code>的出发点是我们对于经常出现的词获取的知识较多，但是对于很少出现的词信息较少，这就导致前者可以学习较多的参数，而后者较少，最终导致每个输出单词的embedding的大小不同。频繁出现的词的embedding较大，而很少出现的词的embedding较小。框架图如图Fig.3所示。</p>
<center><img src="/img/daily/softmax3.png" width="50%"></center><br><center>Fig.3 Differentiated Softmax [Chen et al., 2015]</center>

<p><code>CNN-Softmax</code>学习产生word embedding的函数，而不是单独学习所有输出单词的embedding，如图Fig.4所示。</p>
<center><img src="/img/daily/softmax4.png" width="40%"></center><br><center>Fig.3 CNN-Softmax [Jozefowicz et al., 2016]</center>

<h3 id="sampling-based-Approaches"><a href="#sampling-based-Approaches" class="headerlink" title="sampling-based Approaches"></a><center><strong>sampling-based Approaches</strong></center></h3><p><code>Margin-based Hinge Loss</code>的出发点是只学习两种分类，一种是正确的词，一种是不正确的词。正确的词的得分较高，不正确的词的得分较低，即最大化：<br>$$<br>\sum_{x\in X}\sum_{w\in V}max{(0,1-f(x)+f(x^{(w)})},<br>$$<br>其中，$x^{(w)}$是一个<code>corrupted</code> window (目标词由任意的词来代替)，$f(x)$是模型输出的分数。</p>
<p><code>Noise Contrastive Estimation</code>的目的是将target word跟noise区分开，如图Fig.5所示。这样语言模型被转化为二分类模型，对于每个词按照一定的噪声分布（比如，unigram）获取$k$个噪声采样点，用logistic regression loss最小化cross-entropy函数。随着$k$数目的增长估计softmax。</p>
<center><img src="/img/daily/softmax5.png" width="80%"></center><br><center>Fig.5 Noise Contrastive Estimation (NCE) [Mnih and Teh, 2012]</center>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要介绍了softmax在word embedding方面的应用，资料来源于&lt;a href=&quot;http://www.slideshare.net/SebastianRuder/softmax-approximations-for-learning-word-embeddings-and-language-modeling-sebastian-ruder&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="daily" scheme="http://cuiyungao.github.io/categories/daily/"/>
    
    
      <category term="NLP" scheme="http://cuiyungao.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>FAIR Open-Sources fastText</title>
    <link href="http://cuiyungao.github.io/2016/08/19/fasttext/"/>
    <id>http://cuiyungao.github.io/2016/08/19/fasttext/</id>
    <published>2016-08-19T09:57:42.000Z</published>
    <updated>2016-08-19T14:38:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>fastText是Facebook AI Research (FAIR) lab设计的library，主要用来创建text representation和进行文本分类（详见<a href="http://arxiv.org/abs/1607.04606" target="_blank" rel="external">论文</a>）。</p>
<a id="more"></a>
<p>fastText结合了几个在NLP和machine learning中最成功的概念，包括<code>bag of n-grams</code>, <code>using subword information</code>,以及<code>sharing information across classes with a hidden representation</code>。为了加速计算速度，fastText采用<code>hierarchical softmax</code>来平衡类的分布。</p>
<p>fastText为了有效地处理有大量种类的数据集，采用了hierarchical classifier，而不是flat structure，使得training和testing的复杂度降到linear或者与类的数目成对数关系。为了解决类的分布不均衡的问题，fastText采用了<code>Huffman algorithm</code>建立tree的方法；结果是比较频繁的种类的树的深度较浅。基于fastText，training的时间可以从几天降低到几秒钟，并且在性能上与state-of-the-art的方法接近，如下表所示。</p>
<center><img src="/img/papers/fasttext1.png" width="100%"></center>

<p>在语言的表示形式上，fastText的表现优于word2vec，结果如下表所示。<mark>那么中文的结果怎样？</mark></p>
<center><img src="/img/papers/fasttext2.png" width="100%"></center>


<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><center><strong>Reference</strong></center></h3><p>[1] <a href="https://code.facebook.com/posts/1438652669495149/fair-open-sources-fasttext" target="_blank" rel="external">FAIR open-sources fastText</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;fastText是Facebook AI Research (FAIR) lab设计的library，主要用来创建text representation和进行文本分类（详见&lt;a href=&quot;http://arxiv.org/abs/1607.04606&quot;&gt;论文&lt;/a&gt;）。&lt;/p&gt;
    
    </summary>
    
      <category term="papers" scheme="http://cuiyungao.github.io/categories/papers/"/>
    
    
      <category term="NLP" scheme="http://cuiyungao.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Supervised Sequence Labeling with Recurrent Neural Networks</title>
    <link href="http://cuiyungao.github.io/2016/08/19/supseq/"/>
    <id>http://cuiyungao.github.io/2016/08/19/supseq/</id>
    <published>2016-08-19T07:00:56.000Z</published>
    <updated>2016-08-22T07:59:34.000Z</updated>
    
    <content type="html"><![CDATA[<p>与传统的<code>supervised pattern recognition</code>不同的是，<code>sequence labeling</code>的单独数据点之间并不是相互独立的，后者的输入和labels都是互相关联的序列。<code>Sequence labeling</code>的目的是确定输出labels的位置和类型。<br><a id="more"></a></p>
<p>RNN对sequence labeling比较有效，因为对上下文信息比较灵活（决定forget和remember什么样的信息）；可以接受不同类型的数据和数据的表示形式；可以在序列扭曲中发现sequential patterns。本文主要介绍LSTM和bi-directional RNN。</p>
<h3 id="Generative-and-Discriminative-Methods"><a href="#Generative-and-Discriminative-Methods" class="headerlink" title="Generative and Discriminative Methods"></a><center><strong>Generative and Discriminative Methods</strong></center></h3><p>直接计算类的概率$p(C_k|x)$的方法被认为是discriminative methods；有些情况下，需要先计算类的条件密度$p(x|C_k)$，基于Bayes’ rule来计算，即$p(C_k|x)=\frac{p(x|C_k)p(C_k)}{p(x)}$，其中$p(x)=\sum_k p(x|C_k)p(C_k)$，这样的方法被认为是<code>generative</code>的方法。<code>Generative methods</code>的好处是每一个类都可以独立于其它的类来进行训练，而<code>discriminative methods</code>在每一次新的类加入时都要被重新训练。但是，后者的分类结果较好，因为它的目标是找到类的边界。文章集中在<code>discriminative sequence labeling</code>。</p>
<p>Sequence classification通常分为三类，越来越细地分为temporal classification, segment classification和sequence classification。Temporal classification中的数据是<code>weakly labelled</code>在target sequences之外；segment classification则是temporal classification的一个特殊例子，数据必须用target sequences来进行<code>strongly labelled</code>；sequence classification则指的是每个输入序列只能对应一个类，比如识别单个的手写字母。</p>
<p>Neural networks当中的activation functions都是可求导的，e.g.，<br>$$<br>\frac{\partial tanh(x)}{\partial x} = 1-tanh(x)^2 \\<br>\frac{\partial \sigma (x)}{\partial x} = \sigma(x)(1-\sigma(x)),<br>$$<br>由于activation functions是将无限的输入域映射到有限的输出域，所以通常也被称为<code>squashing functions</code>。</p>
<h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a><center><strong>RNN</strong></center></h3><p>RNN跟Neural Network的不同之处在于NN只能从输入映射到输入，而RNN可以将历史输入映射到输出，也就是说RNN可以将历史的输入保存在网络的中间状态，并影响到网络的输出。<br>Forward Pass:假设时间$t$输入$i$的值为$x_i^t$，$a_j^t$和$b_j^t$分别是时间$t$对单元$j$的输入和激活函数。对于隐含单元，有：<br>$$<br>a_h^t = \sum_{i=1}^I w_{ih}x_i^t + \sum_{h^{\prime}=1}^H w_{h^{\prime}h}b_{h^{\prime}}^{t-1},<br>$$<br>其中，$b_h^t=\theta_h(a_h^t)$，研究发现$b_i^0$初始化成非零的值效果会更好一些。从隐含层到输出层可以由下式得到：<br>$$<br>a_k^t = \sum_{h=1}^H w_{hk}b_h^t。<br>$$</p>
<p>Backward Pass:权重的更新通常有两种方法，<code>real time recurrent learning</code> (RTRL)和<code>backpropagation through time</code> (BPTT)。文章主要关注后者，因为后者概念上更简单，而且在计算时间上更高效（虽然memory上不是很高效）。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;与传统的&lt;code&gt;supervised pattern recognition&lt;/code&gt;不同的是，&lt;code&gt;sequence labeling&lt;/code&gt;的单独数据点之间并不是相互独立的，后者的输入和labels都是互相关联的序列。&lt;code&gt;Sequence labeling&lt;/code&gt;的目的是确定输出labels的位置和类型。&lt;br&gt;
    
    </summary>
    
      <category term="papers" scheme="http://cuiyungao.github.io/categories/papers/"/>
    
    
      <category term="RNN" scheme="http://cuiyungao.github.io/tags/RNN/"/>
    
      <category term="NLP" scheme="http://cuiyungao.github.io/tags/NLP/"/>
    
      <category term="Sequence Labeling" scheme="http://cuiyungao.github.io/tags/Sequence-Labeling/"/>
    
  </entry>
  
  <entry>
    <title>Sequence Labeling</title>
    <link href="http://cuiyungao.github.io/2016/08/19/sequence/"/>
    <id>http://cuiyungao.github.io/2016/08/19/sequence/</id>
    <published>2016-08-19T03:01:09.000Z</published>
    <updated>2016-09-02T08:32:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>总结了UIUC CS498JH: Introduction to NLP (Fall 2012)关于sequence labeling的<a href="https://courses.engr.illinois.edu/cs498jh/Slides/Lecture08HO.pdf" target="_blank" rel="external">课件</a>。</p>
<a id="more"></a>
<p>Sequence labeling包含4个基本任务，即<code>POS tagging</code>，<code>NP chunking</code>，<code>shallow parsing</code>和<code>named entity recognition</code>。这里的<code>discriminative model</code>可以理解为<code>generative model</code>，也就是根据当前word生成其种类，主要用到了<code>maximum entropy classifiers</code>和<code>MEMMs</code>。</p>
<h3 id="Tasks-in-Sequence-Labeling"><a href="#Tasks-in-Sequence-Labeling" class="headerlink" title="Tasks in Sequence Labeling"></a><center><strong>Tasks in Sequence Labeling</strong></center></h3><p>POS tagging是给每个词定义词性，如Fig.1所示。NP chunking是识别所有的名词词组，如Fig.2所示。</p>
<center><img src="/img/daily/sequence1.png" width="70%"></center><br><center>Fig.1 POS Tagging</center>

<center><img src="/img/daily/sequence2.png" width="70%"></center><br><center>Fig.2 NP Chunking</center><br>更具体地，我们定义三种新的tag，如图Fig.3：<br>- B-NP:名词词组的开头；<br>- I-NP:名词词组的中间；<br>- O:名词词组的外面。<br><br><center><img src="/img/daily/sequence3.png" width="70%"></center><br><center>Fig.3 BIO Encoding</center>

<p>Shallow parsing识别所有的non-resursive的名词词组，包括动词词组(“VP”)和介词词组(“PP”)。Named entity recognition则找到所有提到的entities，比如people, organizations, locations和dates。这两种tasks都有BIO encoding的表示形式。</p>
<h3 id="Graphical-Models"><a href="#Graphical-Models" class="headerlink" title="Graphical Models"></a><center><strong>Graphical Models</strong></center></h3><p>Graphical models是概率模型的表示形式，<code>Nodes</code>表示任意变量的分布$P(X)$,<code>Arrows</code>表示依赖关系$P(Y)P(X|Y)$,<code>shaded nodes</code>表示观察到的变量，<code>white nodes</code>表示隐含变量。HMMs可以看做是对输入$\mathbf{w}$的generative models，即$P(\mathbf{w})=\prod_i P(t_i|t_{i-1})P(w_i|t_i)$，如图Fig.4所示。</p>
<center><img src="/img/daily/sequence4.png" width="70%"></center><br><center>Fig.4 HMMs as Generative Models</center>

<p>Sequence Labeling的<mark>定义</mark>是给定输入序列$\mathbf{w}=w_1, …, w_n$，预测其最佳的label sequence $\mathbf{t}=t_1, …, t_n$，即：<br>$$<br>{argmax}_{\substack{t}}P(\mathbf{t}|\mathbf{w}).<br>$$<br>我们用<code>conditional maximum likelihood estimation</code> (conditional MLE)来估计$w$，<br>$$<br>\begin{aligned}<br>\hat{\mathbf{w}}&amp;={argmax}_{\substack{\mathbf{w}}}\prod_i P(c_i|\mathbf{x}_i,\mathbf{w})\\<br>  &amp;= {argmax}_{\substack{\mathbf{w}}}\sum_i log(P(c_i|\mathbf{x}_i,\mathbf{w})) \\<br>  &amp;= {argmax}_{\substack{\mathbf{w}}}\sum_i log(\frac{e^{\sum_j w_j f_j(x_i,c)}}{\sum_{c^{\prime}e^{\sum_j w_j f_j(x_i,c^{\prime})}}}) \\<br>  &amp;= {argmax}_{\substack{\mathbf{w}}}(L_{\mathbf{w}})<br> \end{aligned}<br>$$<br>对其进行求导，我们可以得到下式。</p>
<center><img src="/img/daily/sequence5.png" width="70%"></center>

<p>假设对$P(\mathbf{w})$建模，假定是高斯（正态）分布，我们可以得到下式。</p>
<center><img src="/img/daily/sequence6.png" width="70%"></center>

<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><center><strong>Reference</strong></center></h3><p>[1] <a href="https://www.zhihu.com/question/46688107" target="_blank" rel="external">CRF和LSTM模型在序列标注上的优劣？</a>总结得很好，当中还提供了源代码，强烈推荐。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结了UIUC CS498JH: Introduction to NLP (Fall 2012)关于sequence labeling的&lt;a href=&quot;https://courses.engr.illinois.edu/cs498jh/Slides/Lecture08HO.pdf&quot;&gt;课件&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="daily" scheme="http://cuiyungao.github.io/categories/daily/"/>
    
    
      <category term="NLP" scheme="http://cuiyungao.github.io/tags/NLP/"/>
    
      <category term="CRF" scheme="http://cuiyungao.github.io/tags/CRF/"/>
    
      <category term="Sequence Labeling" scheme="http://cuiyungao.github.io/tags/Sequence-Labeling/"/>
    
  </entry>
  
</feed>
